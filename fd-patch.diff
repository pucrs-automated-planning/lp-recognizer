diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/fast-downward fast-downward/fast-downward
--- fast-downward-original/fast-downward	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/fast-downward	2021-03-18 23:58:56.032311200 -0300
@@ -0,0 +1,13 @@
+#!/usr/bin/env bash
+DIR=`dirname $0`
+DOMAIN=$1
+shift
+PROBLEM=$1
+shift
+# ${DIR}/fast-downward.py $DOMAIN $PROBLEM --search "astar(lmcut())" "$@"
+# ${DIR}/fast-downward.py $DOMAIN $PROBLEM --search "astar(seq())" "$@"
+# ${DIR}/fast-downward.py --build=release64 $DOMAIN $PROBLEM --search "astar(operatorcounting([lmcut_constraints()], lpsolver=CPLEX, transform=no_transform(), cache_estimates=true))" "$@"
+# ${DIR}/fast-downward.py --build=release64 $DOMAIN $PROBLEM --search "astar(operatorcounting([lmcut_constraints(), pho_constraints(), state_equation_constraints()]))" "$@"
+${DIR}/fast-downward.py --build=release $DOMAIN $PROBLEM --search "astar(operatorcounting([lmcut_constraints(), pho_constraints(), state_equation_constraints()]))" "$@"
+
+# ${DIR}/fast-downward.py $DOMAIN $PROBLEM --alias seq-opt-lmcut "$@"
\ No newline at end of file
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/DownwardFiles.cmake fast-downward/src/search/DownwardFiles.cmake
--- fast-downward-original/src/search/DownwardFiles.cmake	2020-10-26 22:55:32.995391700 -0300
+++ fast-downward/src/search/DownwardFiles.cmake	2021-03-18 23:58:06.063374900 -0300
@@ -703,6 +703,10 @@
         operator_counting/operator_counting_heuristic
         operator_counting/pho_constraints
         operator_counting/state_equation_constraints
+        operator_counting/delete_relaxation_constraints
+        operator_counting/flow_constraints
+        operator_counting/flow_constraint_internals
+        operator_counting/oc_single_shot_heuristic
     DEPENDS LP_SOLVER LANDMARK_CUT_HEURISTIC PDBS TASK_PROPERTIES
 )
 
@@ -713,6 +717,7 @@
         pdbs/canonical_pdbs
         pdbs/canonical_pdbs_heuristic
         pdbs/dominance_pruning
+        pdbs/explicit_projection
         pdbs/incremental_canonical_pdbs
         pdbs/match_tree
         pdbs/max_cliques
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/algorithms/combinations.h fast-downward/src/search/algorithms/combinations.h
--- fast-downward-original/src/search/algorithms/combinations.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/algorithms/combinations.h	2021-03-18 23:58:06.063374900 -0300
@@ -0,0 +1,45 @@
+#ifndef ALGORITHMS_COMBINATIONS_H
+#define ALGORITHMS_COMBINATIONS_H
+
+#include "../task_proxy.h"
+#include "../utils/logging.h"
+#include "../utils/collections.h"
+
+#include <cassert>
+#include <iostream>
+#include <vector>
+
+template<typename T>
+class Combinations {
+     std::vector<T> current_combination;
+     std::vector<std::vector<T>> combinations;
+
+     void add_combinations(const std::vector<T> &sequence, int offset, int k) {
+         if (k == 0) {
+             combinations.push_back(current_combination);
+             return;
+         }
+         for (size_t i = offset; i <= sequence.size() - k; ++i) {
+             assert(utils::in_bounds(i, sequence));
+             current_combination.push_back(sequence[i]);
+             add_combinations(sequence, i + 1, k - 1);
+             current_combination.pop_back();
+         }
+     }
+
+public:
+     std::vector<std::vector<T>> && get_combinations(
+         const std::vector<T> &sequence, int k) {
+         assert(k >= 0);
+         combinations.clear();
+         current_combination.clear();
+         int n = sequence.size();
+         if (k > n) {
+             return std::move(combinations);
+         }
+         add_combinations(sequence, 0, k);
+         return std::move(combinations);
+     }
+};
+
+#endif
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/heuristics/lm_cut_landmarks.cc fast-downward/src/search/heuristics/lm_cut_landmarks.cc
--- fast-downward-original/src/search/heuristics/lm_cut_landmarks.cc	2020-10-26 22:55:30.681229000 -0300
+++ fast-downward/src/search/heuristics/lm_cut_landmarks.cc	2021-03-18 23:58:06.095008100 -0300
@@ -10,6 +10,60 @@
 
 namespace lm_cut_heuristic {
 // construction and destruction
+
+LandmarkCutLandmarks::LandmarkCutLandmarks(const TaskProxy &task_proxy, const vector<int> &observations) {
+    task_properties::verify_no_axioms(task_proxy);
+    task_properties::verify_no_conditional_effects(task_proxy);
+
+    // Build propositions.
+    num_propositions = 2; // artificial goal and artificial precondition
+    VariablesProxy variables = task_proxy.get_variables();
+    propositions.resize(variables.size());
+    for (FactProxy fact : variables.get_facts()) {
+        int var_id = fact.get_variable().get_id();
+        propositions[var_id].push_back(RelaxedProposition());
+        ++num_propositions;
+    }
+
+    // Build relaxed operators for operators and axioms.
+    for (OperatorProxy op : task_proxy.get_operators())
+        build_relaxed_operator(op);
+
+    // Simplify relaxed operators.
+    // simplify();
+    /* TODO: Put this back in and test if it makes sense,
+       but only after trying out whether and how much the change to
+       unary operators hurts. */
+
+    // Build artificial goal proposition and operator.
+    vector<RelaxedProposition *> goal_op_pre, goal_op_eff;
+    for (FactProxy goal : task_proxy.get_goals()) {
+        goal_op_pre.push_back(get_proposition(goal));
+    }
+    cout << "Observation preconditions: " << endl;
+    for (int op_id : observations) {
+        for (FactProxy f : task_proxy.get_operators()[op_id].get_preconditions()) {
+            RelaxedProposition *pre = get_proposition(f);
+            if (std::find(goal_op_pre.begin(), goal_op_pre.end(), pre) == goal_op_pre.end()) {
+                goal_op_pre.push_back(pre);
+                cout << f.get_name() << endl;
+            }
+        }
+    }
+    goal_op_eff.push_back(&artificial_goal);
+    /* Use the invalid operator ID -1 so accessing
+       the artificial operator will generate an error. */
+    add_relaxed_operator(move(goal_op_pre), move(goal_op_eff), -1, 0);
+
+    // Cross-reference relaxed operators.
+    for (RelaxedOperator &op : relaxed_operators) {
+        for (RelaxedProposition *pre : op.preconditions)
+            pre->precondition_of.push_back(&op);
+        for (RelaxedProposition *eff : op.effects)
+            eff->effect_of.push_back(&op);
+    }
+}
+
 LandmarkCutLandmarks::LandmarkCutLandmarks(const TaskProxy &task_proxy) {
     task_properties::verify_no_axioms(task_proxy);
     task_properties::verify_no_conditional_effects(task_proxy);
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/heuristics/lm_cut_landmarks.h fast-downward/src/search/heuristics/lm_cut_landmarks.h
--- fast-downward-original/src/search/heuristics/lm_cut_landmarks.h	2020-10-26 22:55:30.685249200 -0300
+++ fast-downward/src/search/heuristics/lm_cut_landmarks.h	2021-03-18 23:58:06.095008100 -0300
@@ -86,6 +86,7 @@
     using LandmarkCallback = std::function<void (const Landmark &, int)>;
 
     LandmarkCutLandmarks(const TaskProxy &task_proxy);
+    LandmarkCutLandmarks(const TaskProxy &task_proxy, const std::vector<int> &observations);
     virtual ~LandmarkCutLandmarks();
 
     /*
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/lp/ip.patch fast-downward/src/search/lp/ip.patch
--- fast-downward-original/src/search/lp/ip.patch	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/lp/ip.patch	2021-03-18 23:58:06.095008100 -0300
@@ -0,0 +1,86 @@
+diff -r 69ad07c0e8c6 -r b106ec3b48b5 src/search/lp/lp_solver.cc
+--- a/src/search/lp/lp_solver.cc	Thu Feb 25 15:37:36 2016 +0100
++++ b/src/search/lp/lp_solver.cc	Thu Feb 25 21:08:36 2016 +0100
+@@ -4,6 +4,7 @@
+ 
+ #include "../option_parser.h"
+ 
++#include "../utils/logging.h"
+ #include "../utils/system.h"
+ 
+ #ifdef USE_LP
+@@ -70,10 +71,11 @@
+ }
+ 
+ LPVariable::LPVariable(double lower_bound_, double upper_bound_,
+-                       double objective_coefficient_)
++                       double objective_coefficient_, bool is_integer_)
+     : lower_bound(lower_bound_),
+       upper_bound(upper_bound_),
+-      objective_coefficient(objective_coefficient_) {
++      objective_coefficient(objective_coefficient_),
++      is_integer(is_integer_) {
+ }
+ 
+ LPVariable::~LPVariable() {
+@@ -162,6 +164,14 @@
+                                objective.data(),
+                                row_lb.data(),
+                                row_ub.data());
++        int num_vars = variables.size();
++        for (int i = 0; i < num_vars; ++i) {
++            if (variables[i].is_integer) {
++                lp_solver->setInteger(i);
++            }
++        }
++        cout << "Integer tolerance: " << lp_solver->getIntegerTolerance() << endl;
++        cout << "Number of integer variables: " << lp_solver->getNumIntegers() << endl;
+     } catch (CoinError &error) {
+         handle_coin_error(error);
+     }
+@@ -303,6 +313,20 @@
+     }
+ }
+ 
++void LPSolver::solve_mip() {
++    try {
++        lp_solver->branchAndBound();
++        if (lp_solver->isAbandoned()) {
++            cerr << "Abandoned LP. "
++                 << "Reasons include \"numerical difficulties\" and running out of memory." << endl;
++            utils::exit_with(ExitCode::CRITICAL_ERROR);
++        }
++        is_solved = true;
++    } catch (CoinError &error) {
++        handle_coin_error(error);
++    }
++}
++
+ bool LPSolver::has_optimal_solution() const {
+     assert(is_solved);
+     try {
+diff -r 69ad07c0e8c6 -r b106ec3b48b5 src/search/lp/lp_solver.h
+--- a/src/search/lp/lp_solver.h	Thu Feb 25 15:37:36 2016 +0100
++++ b/src/search/lp/lp_solver.h	Thu Feb 25 21:08:36 2016 +0100
+@@ -68,10 +68,12 @@
+     double lower_bound;
+     double upper_bound;
+     double objective_coefficient;
++    bool is_integer;
+ 
+     LPVariable(double lower_bound_,
+                double upper_bound_,
+-               double objective_coefficient_);
++               double objective_coefficient_,
++               bool is_integer_ = false);
+     ~LPVariable();
+ };
+ 
+@@ -128,6 +130,7 @@
+     LP_METHOD(void set_variable_upper_bound(int index, double bound))
+ 
+     LP_METHOD(void solve())
++    LP_METHOD(void solve_mip())
+ 
+     /*
+       Return true if the solving the LP showed that it is bounded feasible and
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/lp/lp_internals.cc fast-downward/src/search/lp/lp_internals.cc
--- fast-downward-original/src/search/lp/lp_internals.cc	2020-10-26 22:55:33.018182500 -0300
+++ fast-downward/src/search/lp/lp_internals.cc	2021-03-18 23:58:06.110269300 -0300
@@ -11,25 +11,31 @@
 #pragma GCC diagnostic ignored "-Woverflow"
 #pragma GCC diagnostic ignored "-Wsign-compare"
 #pragma GCC diagnostic ignored "-Wunused-parameter"
+#pragma GCC diagnostic ignored "-Wregister"
 #if __GNUC__ >= 6
 #pragma GCC diagnostic ignored "-Wmisleading-indentation"
+#pragma GCC diagnostic ignored "-Wregister"
 #endif
 #endif
 #ifdef __clang__
 #pragma GCC diagnostic ignored "-Wconstant-conversion"
+#pragma GCC diagnostic ignored "-Wregister"
 #endif
 #include <OsiSolverInterface.hpp>
 
 #ifdef COIN_HAS_CLP
+#pragma GCC diagnostic ignored "-Wregister"
 #include <OsiClpSolverInterface.hpp>
 #endif
 
 #ifdef COIN_HAS_CPX
+#pragma GCC diagnostic ignored "-Wregister"
 #include <OsiCpxSolverInterface.hpp>
 #include <cplex.h>
 #endif
 
 #ifdef COIN_HAS_GRB
+#pragma GCC diagnostic ignored "-Wregister"
 #include <OsiGrbSolverInterface.hpp>
 #endif
 
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/lp/lp_solver.cc fast-downward/src/search/lp/lp_solver.cc
--- fast-downward-original/src/search/lp/lp_solver.cc	2020-10-26 22:55:33.021390200 -0300
+++ fast-downward/src/search/lp/lp_solver.cc	2021-03-18 23:58:06.110269300 -0300
@@ -21,6 +21,8 @@
 #endif
 
 #include <cassert>
+#include <cmath>
+#include <memory>
 #include <numeric>
 
 using namespace std;
@@ -70,20 +72,21 @@
 }
 
 LPVariable::LPVariable(double lower_bound, double upper_bound,
-                       double objective_coefficient)
+                       double objective_coefficient, bool is_integer)
     : lower_bound(lower_bound),
       upper_bound(upper_bound),
-      objective_coefficient(objective_coefficient) {
-}
+      objective_coefficient(objective_coefficient),
+      is_integer(is_integer) {}
 
 LPSolver::~LPSolver() {
 }
 
 #ifdef USE_LP
 
-LPSolver::LPSolver(LPSolverType solver_type)
+LPSolver::LPSolver(LPSolverType solver_type, bool mip)
     : is_initialized(false),
       is_solved(false),
+      mip(mip),
       num_permanent_constraints(0),
       has_temporary_constraints_(false) {
     lp_solver = create_lp_solver(solver_type);
@@ -118,6 +121,12 @@
         row_ub.push_back(constraint.get_upper_bound());
     }
 
+    if (sense == LPObjectiveSense::MINIMIZE) {
+        lp_solver->setObjSense(1);
+    } else {
+        lp_solver->setObjSense(-1);
+    }
+
     for (const LPConstraint &constraint : constraints) {
         const vector<int> &vars = constraint.get_variables();
         const vector<double> &coeffs = constraint.get_coefficients();
@@ -153,6 +162,18 @@
                                objective.data(),
                                row_lb.data(),
                                row_ub.data());
+        cout << "Matrix size: " << lp_solver->getNumCols() << " x " << lp_solver->getNumRows() << endl;
+        int num_vars = variables.size();
+        if (mip) {
+            for (int i = 0; i < num_vars; ++i) {
+                if (variables[i].is_integer) {
+                    lp_solver->setInteger(i);
+                }
+            }
+        }
+        // cout << "Integer tolerance: " << lp_solver->getIntegerTolerance() <<
+        // endl; cout << "Number of integer variables: " <<
+        // lp_solver->getNumIntegers() << endl;
         /*
           We set the objective sense after loading because the SoPlex
           interfaces of all OSI versions <= 0.108.4 ignore it when it is
@@ -263,6 +284,16 @@
     is_solved = false;
 }
 
+void LPSolver::set_constraint_bounds(int index, double lower, double upper) {
+    assert(index < get_num_constraints());
+    try {
+        lp_solver->setRowBounds(index, lower, upper);
+    } catch (CoinError &error) {
+        handle_coin_error(error);
+    }
+    is_solved = false;
+}
+
 void LPSolver::set_variable_lower_bound(int index, double bound) {
     assert(index < get_num_variables());
     try {
@@ -285,17 +316,22 @@
 
 void LPSolver::solve() {
     try {
-        if (is_initialized) {
-            lp_solver->resolve();
+        if (mip) {
+            lp_solver->branchAndBound();
         } else {
-            lp_solver->initialSolve();
-            is_initialized = true;
+            if (is_initialized) {
+                lp_solver->resolve();
+            } else {
+                lp_solver->initialSolve();
+                is_initialized = true;
+            }
         }
         if (lp_solver->isAbandoned()) {
             // The documentation of OSI is not very clear here but memory seems
             // to be the most common cause for this in our case.
             cerr << "Abandoned LP during resolve. "
-                 << "Reasons include \"numerical difficulties\" and running out of memory." << endl;
+                 << "Reasons include \"numerical difficulties\" and running out of memory."
+                 << endl;
             utils::exit_with(ExitCode::SEARCH_CRITICAL_ERROR);
         }
         is_solved = true;
@@ -334,6 +370,24 @@
     }
 }
 
+bool LPSolver::is_solution_integral() const {
+    assert(has_optimal_solution());
+    double epsilon = 0.01;
+    try {
+        const double *sol = lp_solver->getColSolution();
+        int num_vars = get_num_variables();
+        for (int i = 0; i < num_vars; ++i) {
+            double value = sol[i];
+            if (abs(value - round(value)) > epsilon) {
+                return false;
+            }
+        }
+        return true;
+    } catch (CoinError &error) {
+        handle_coin_error(error);
+    }
+}
+
 int LPSolver::get_num_variables() const {
     try {
         return lp_solver->getNumCols();
@@ -360,4 +414,4 @@
 }
 
 #endif
-}
+}  // namespace lp
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/lp/lp_solver.h fast-downward/src/search/lp/lp_solver.h
--- fast-downward-original/src/search/lp/lp_solver.h	2020-10-26 22:55:33.025379300 -0300
+++ fast-downward/src/search/lp/lp_solver.h	2021-03-18 23:58:06.126212800 -0300
@@ -46,6 +46,7 @@
     std::vector<double> coefficients;
     double lower_bound;
     double upper_bound;
+
 public:
     LPConstraint(double lower_bound, double upper_bound);
 
@@ -67,10 +68,12 @@
     double lower_bound;
     double upper_bound;
     double objective_coefficient;
+    bool is_integer;
 
     LPVariable(double lower_bound,
                double upper_bound,
-               double objective_coefficient);
+               double objective_coefficient,
+               bool is_integer = false);
 };
 
 #ifdef __GNUG__
@@ -80,6 +83,7 @@
 class LPSolver {
     bool is_initialized;
     bool is_solved;
+    bool mip;
     int num_permanent_constraints;
     bool has_temporary_constraints_;
 #ifdef USE_LP
@@ -100,8 +104,9 @@
     std::vector<double> row_ub;
     std::vector<CoinPackedVectorBase *> rows;
     void clear_temporary_data();
+
 public:
-    LP_METHOD(explicit LPSolver(LPSolverType solver_type))
+    LP_METHOD(explicit LPSolver(LPSolverType solver_type, bool mip = false))
     /*
       Note that the destructor does not use LP_METHOD because it should not
       have the attribute NO_RETURN. It also cannot be set to the default
@@ -122,6 +127,7 @@
     LP_METHOD(void set_objective_coefficient(int index, double coefficient))
     LP_METHOD(void set_constraint_lower_bound(int index, double bound))
     LP_METHOD(void set_constraint_upper_bound(int index, double bound))
+    LP_METHOD(void set_constraint_bounds(int index, double lower, double upper))
     LP_METHOD(void set_variable_lower_bound(int index, double bound))
     LP_METHOD(void set_variable_upper_bound(int index, double bound))
 
@@ -144,6 +150,11 @@
     LP_METHOD(double get_objective_value() const)
 
     /*
+      Return true iff all variables in the solution have an integer value.
+    */
+    LP_METHOD(bool is_solution_integral() const)
+
+    /*
       Return the solution found after solving an LP as a vector with one entry
       per variable.
       The LP has to be solved with a call to solve() and has to have an optimal
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/constraint_generator.cc fast-downward/src/search/operator_counting/constraint_generator.cc
--- fast-downward-original/src/search/operator_counting/constraint_generator.cc	2020-10-26 22:55:33.057730200 -0300
+++ fast-downward/src/search/operator_counting/constraint_generator.cc	2021-03-18 23:58:06.126212800 -0300
@@ -6,7 +6,12 @@
 
 namespace operator_counting {
 void ConstraintGenerator::initialize_constraints(
-    const shared_ptr<AbstractTask> &, vector<lp::LPConstraint> &, double) {
+    const shared_ptr<AbstractTask> &, vector<lp::LPVariable> &, vector<lp::LPConstraint> &, double) {
+}
+
+void ConstraintGenerator::set_observations(const vector<int>& observations, int obs_info) {
+	this->obs_info = obs_info;
+	this->observations = observations;
 }
 
 static PluginTypePlugin<ConstraintGenerator> _type_plugin(
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/constraint_generator.h fast-downward/src/search/operator_counting/constraint_generator.h
--- fast-downward-original/src/search/operator_counting/constraint_generator.h	2020-10-26 22:55:33.062373200 -0300
+++ fast-downward/src/search/operator_counting/constraint_generator.h	2021-03-18 23:58:06.126212800 -0300
@@ -10,6 +10,12 @@
 namespace lp {
 class LPConstraint;
 class LPSolver;
+class LPVariable;
+}
+
+namespace options {
+class OptionParser;
+class Options;
 }
 
 namespace operator_counting {
@@ -27,10 +33,12 @@
       Example: constraints from landmarks generated for a given state, e.g.
       using the LM-Cut method.
 */
+
 class ConstraintGenerator {
 public:
+    std::vector<int> observations;
+    int obs_info = 0;
     virtual ~ConstraintGenerator() = default;
-
     /*
       Called upon initialization for the given task. Use this to add permanent
       constraints and perform other initialization. The parameter "infinity"
@@ -39,6 +47,7 @@
     */
     virtual void initialize_constraints(
         const std::shared_ptr<AbstractTask> &task,
+        std::vector<lp::LPVariable> &variables,
         std::vector<lp::LPConstraint> &constraints,
         double infinity);
 
@@ -51,6 +60,8 @@
     */
     virtual bool update_constraints(const State &state,
                                     lp::LPSolver &lp_solver) = 0;
+
+    void set_observations(const std::vector<int>& observations, int obs_info = 0);
 };
 }
 
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/delete_relaxation_constraints.cc fast-downward/src/search/operator_counting/delete_relaxation_constraints.cc
--- fast-downward-original/src/search/operator_counting/delete_relaxation_constraints.cc	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/delete_relaxation_constraints.cc	2021-03-18 23:58:06.141479900 -0300
@@ -0,0 +1,306 @@
+#include "delete_relaxation_constraints.h"
+
+#include "../option_parser.h"
+#include "../plugin.h"
+
+#include "../task_proxy.h"
+
+#include "../lp/lp_solver.h"
+
+#include <cassert>
+
+using namespace std;
+
+namespace operator_counting {
+
+DeleteRelaxationConstraints::DeleteRelaxationConstraints(const Options &opts)
+    : use_time_vars(opts.get<bool>("use_time_vars")),
+    use_integer_vars_op(opts.get<int>("use_integer_vars_op")),
+    use_integer_vars_facts(opts.get<int>("use_integer_vars_facts")),
+    use_integer_vars_achiever(opts.get<int>("use_integer_vars_achiever")),
+    use_integer_vars_time(opts.get<int>("use_integer_vars_time")) {
+}
+
+int DeleteRelaxationConstraints::get_var_op_used(OperatorProxy op) {
+    return lp_var_id_op_used[op.get_id()];
+}
+
+int DeleteRelaxationConstraints::get_var_op_used2(OperatorProxy op) {
+    return lp_var_id_op_used2[op.get_id()];
+}
+
+int DeleteRelaxationConstraints::get_var_fact_reached(FactProxy f) {
+    return lp_var_id_fact_reached[f.get_variable().get_id()][f.get_value()];
+}
+
+int DeleteRelaxationConstraints::get_var_first_achiever(OperatorProxy op, FactProxy f) {
+    return lp_var_id_first_achiever[op.get_id()][f.get_variable().get_id()][f.get_value()];
+}
+
+int DeleteRelaxationConstraints::get_var_op_time(OperatorProxy op) {
+    return lp_var_id_op_time[op.get_id()];
+}
+
+int DeleteRelaxationConstraints::get_var_op_time2(OperatorProxy op) {
+    return lp_var_id_op_time2[op.get_id()];
+}
+
+int DeleteRelaxationConstraints::get_var_fact_time(FactProxy f) {
+    return lp_var_id_fact_time[f.get_variable().get_id()][f.get_value()];
+}
+
+int DeleteRelaxationConstraints::get_constraint_id(FactProxy f) {
+    return constraint_ids[f.get_variable().get_id()][f.get_value()];
+}
+
+void add_lp_variables(int count, vector<bool>& obs_used,
+        vector<lp::LPVariable> &variables, vector<int> &indices,
+        double lower, double upper, double objective, int is_integer) {
+    for (int i = 0; i < count; ++i) {
+        indices.push_back(variables.size());
+        variables.emplace_back(lower, upper, objective, is_integer == 1 || is_integer == 2 && obs_used[i]);
+    }
+}
+
+void DeleteRelaxationConstraints::create_auxiliary_variables(
+    TaskProxy task_proxy, vector<lp::LPVariable> &variables) {
+    OperatorsProxy ops = task_proxy.get_operators();
+    int num_ops = ops.size();
+    VariablesProxy vars = task_proxy.get_variables();
+    int num_vars = vars.size();
+
+    vector<bool> obs_used(num_ops, false);
+    for (int id : observations)
+        obs_used[id] = true;
+
+    // op_used
+    add_lp_variables(num_ops, obs_used, variables, lp_var_id_op_used, 0, 1, 0, use_integer_vars_op);
+    if (obs_info)
+        add_lp_variables(num_ops, obs_used, variables, lp_var_id_op_used2, 0, 1, 0, use_integer_vars_op);
+
+    // fact_reached
+    lp_var_id_fact_reached.resize(num_vars);
+    for (VariableProxy var : vars) {
+        add_lp_variables(var.get_domain_size(), obs_used, variables,
+                         lp_var_id_fact_reached[var.get_id()],
+                         0, 1, 0, use_integer_vars_facts == 1);
+    }
+
+    // first_achiever
+    lp_var_id_first_achiever.resize(num_ops);
+    for (OperatorProxy op : ops) {
+        bool is_integer = use_integer_vars_achiever == 1 || use_integer_vars_achiever == 2 && obs_used[op.get_id()];
+        lp_var_id_first_achiever[op.get_id()].resize(num_vars);
+        for (VariableProxy var : vars) {
+            add_lp_variables(var.get_domain_size(), obs_used, variables,
+                             lp_var_id_first_achiever[op.get_id()][var.get_id()],
+                             0, 1, 0, is_integer);
+        }
+    }
+
+    if (use_time_vars) {
+        // op_time
+        add_lp_variables(num_ops, obs_used, variables, lp_var_id_op_time, 0, num_ops, 0, use_integer_vars_time);
+
+        // fact_time
+        lp_var_id_fact_time.resize(num_vars);
+        for (VariableProxy var : vars) {
+            add_lp_variables(var.get_domain_size(), obs_used, variables,
+                             lp_var_id_fact_time[var.get_id()],
+                             0, num_ops, 0, use_integer_vars_time == 1);
+        }
+    }
+}
+
+void DeleteRelaxationConstraints::create_constraints(
+    TaskProxy task_proxy, vector<lp::LPVariable> &variables,
+    vector<lp::LPConstraint> &constraints, double infinity) {
+    OperatorsProxy ops = task_proxy.get_operators();
+    VariablesProxy vars = task_proxy.get_variables();
+
+    // All goal facts must be reached (handled in variable bound instead of constraint).
+    // R_f = 1 for all goal facts f.
+    for (FactProxy goal : task_proxy.get_goals()) {
+        variables[get_var_fact_reached(goal)].lower_bound = 1;
+        //cout << "Goal fact reached: " << goal.get_name() << endl;
+    }
+
+    // A fact is reached if it has a first achiever or is true in the current state.
+    // sum_{o \in achievers(f)} F_{o,f} - R_f >= [s |= f] for each fact f.
+    constraint_ids.resize(vars.size());
+    for (VariableProxy var : vars) {
+        constraint_ids[var.get_id()].resize(var.get_domain_size());
+        for (int value = 0; value < var.get_domain_size(); ++value) {
+            constraint_ids[var.get_id()][value] = constraints.size();
+            constraints.emplace_back(0, infinity);
+            /* The constraint is:
+
+               We add "- R_f" here, collect the achiever below and adapt
+               the lower bound in each iteration, i.e., in update_constraints. */
+            constraints.back().insert(get_var_fact_reached(var.get_fact(value)), -1);
+
+        }
+    }
+    for (OperatorProxy op : ops) {
+        for (EffectProxy eff : op.get_effects()) {
+            FactProxy f = eff.get_fact();
+            lp::LPConstraint &constraint = constraints[get_constraint_id(f)];
+            constraint.insert(get_var_first_achiever(op, f), 1);
+            //cout << "Fact achievers: " << f.get_name() << " " << op.get_name() << endl;
+        }
+    }
+
+
+    // If an operator is a first achiever, it must be used.
+    // U_o >= F_{o,f} for each operator o and each of its effects f.
+    for (OperatorProxy op : ops) {
+        for (EffectProxy eff : op.get_effects()) {
+            FactProxy f = eff.get_fact();
+            lp::LPConstraint constraint(0, infinity);
+            constraint.insert(get_var_op_used(op), 1);
+            constraint.insert(get_var_first_achiever(op, f), -1);
+            constraints.push_back(constraint);
+            //cout << "First achieved used: " << f.get_name() << " " << op.get_name() << endl;
+        }
+    }
+
+    // If an operator is used, its preconditions must be reached.
+    // R_f >= U_o for each operator o and each of its preconditions f.
+    for (OperatorProxy op : ops) {
+        for (FactProxy f : op.get_preconditions()) {
+            lp::LPConstraint constraint(0, infinity);
+            constraint.insert(get_var_fact_reached(f), 1);
+            constraint.insert(get_var_op_used(op), -1);
+            constraints.push_back(constraint);
+            //cout << "Precondition: " << op.get_name() << " " << f.get_name() << endl;
+        }
+    }
+
+    // Observed operators
+    for (int obs : observations) {
+        int var = get_var_op_used(ops[obs]);
+        variables[var].lower_bound = 1;
+    }
+
+    if (use_time_vars) {
+        // Preconditions must be reached before the operator is used.
+        // T_f <= T_o for each operator o and each of its preconditions f.
+        for (OperatorProxy op : ops) {
+            for (FactProxy f : op.get_preconditions()) {
+                lp::LPConstraint constraint(0, infinity);
+                constraint.insert(get_var_op_time(op), 1);
+                constraint.insert(get_var_fact_time(f), -1);
+                constraints.push_back(constraint);
+            }
+        }
+
+        if (obs_info) {
+            int N = ops.size();
+            vector<int> first_obs;
+            for (int obs : observations)
+                if (find(first_obs.begin(), first_obs.end(), obs) == first_obs.end())
+                    first_obs.push_back(obs);
+            for (uint i = 1; i < first_obs.size(); i++) {
+                OperatorProxy op1 = ops[first_obs[i-1]];
+                OperatorProxy op2 = ops[first_obs[i]];
+                lp::LPConstraint constraint(1, infinity);
+                constraint.insert(get_var_op_time(op2), 1);
+                constraint.insert(get_var_op_time(op1), -1);
+                constraint.insert(get_var_op_used2(op2), N);
+                constraints.push_back(constraint);
+            }
+        }
+
+        // If an operator is a first achiever, its effects are reached in the time step following its use.
+        // T_o + 1 <= T_f + M(1 - F_{o,f}) for each operator o and each of its effects f.
+        // <--->  1 - M <= T_f - T_o - M*F_{o,f} <= infty
+        int M = ops.size() + 1;
+        for (OperatorProxy op : ops) {
+            for (EffectProxy eff : op.get_effects()) {
+                FactProxy f = eff.get_fact();
+                lp::LPConstraint constraint(1-M, infinity);
+                constraint.insert(get_var_fact_time(f), 1);
+                constraint.insert(get_var_op_time(op), -1);
+                constraint.insert(get_var_first_achiever(op, f), -M);
+                constraints.push_back(constraint);
+            }
+        }
+    }
+
+    // If an operator is used, it must occur at least once.
+    // U_o <= C_o for each operator o.
+    for (OperatorProxy op : ops) {
+        lp::LPConstraint constraint(0, infinity);
+        constraint.insert(op.get_id(), 1);
+        constraint.insert(get_var_op_used(op), -1);
+        if (obs_info)
+            constraint.insert(get_var_op_used2(op), -1);
+        constraints.push_back(constraint);
+
+        //lp::LPConstraint constraint_inv(0, infinity);
+        //constraint.insert(op.get_id(), -1);
+        //constraint.insert(get_var_op_used(op), 10000000);
+        //constraints.push_back(constraint);
+    }
+}
+
+
+void DeleteRelaxationConstraints::initialize_constraints(
+    const shared_ptr<AbstractTask> &task,
+    vector<lp::LPVariable> &variables, vector<lp::LPConstraint> &constraints,
+    double infinity) {
+    TaskProxy task_proxy(*task);
+    create_auxiliary_variables(task_proxy, variables);
+    create_constraints(task_proxy, variables, constraints, infinity);
+}
+
+
+bool DeleteRelaxationConstraints::update_constraints(const State &state, lp::LPSolver &lp_solver) {
+    // Unset old bounds.
+    for (FactProxy f : last_state) {
+        lp_solver.set_constraint_lower_bound(get_constraint_id(f), 0);
+    }
+    last_state.clear();
+    // Set new bounds.
+    for (FactProxy f : state) {
+        lp_solver.set_constraint_lower_bound(get_constraint_id(f), -1);
+        last_state.push_back(f);
+    }
+    return false;
+}
+
+static shared_ptr<ConstraintGenerator> _parse(OptionParser &parser) {
+    parser.add_option<bool>(
+        "use_time_vars",
+        "use variables for time steps (setting this to false is the time relaxation by Imai and Fukunaga)",
+        "true"
+    );
+    parser.add_option<int>(
+        "use_integer_vars_op",
+        "auxilliary variables will be restricted to integer values",
+        "1"
+    );
+    parser.add_option<int>(
+        "use_integer_vars_facts",
+        "auxilliary variables will be restricted to integer values",
+        "1"
+    );
+    parser.add_option<int>(
+        "use_integer_vars_achiever",
+        "auxilliary variables will be restricted to integer values",
+        "1"
+    );
+    parser.add_option<int>(
+        "use_integer_vars_time",
+        "auxilliary variables will be restricted to integer values",
+        "1"
+    );
+    Options opts = parser.parse();
+
+    if (parser.dry_run())
+        return nullptr;
+    return make_shared<DeleteRelaxationConstraints>(opts);
+}
+
+static Plugin<ConstraintGenerator> _plugin("delete_relaxation_constraints", _parse);
+}
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/delete_relaxation_constraints.h fast-downward/src/search/operator_counting/delete_relaxation_constraints.h
--- fast-downward-original/src/search/operator_counting/delete_relaxation_constraints.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/delete_relaxation_constraints.h	2021-03-18 23:58:06.141479900 -0300
@@ -0,0 +1,72 @@
+#ifndef OPERATOR_COUNTING_DELETE_RELAXATION_CONSTRAINTS_H
+#define OPERATOR_COUNTING_DELETE_RELAXATION_CONSTRAINTS_H
+
+#include  "constraint_generator.h"
+
+#include "../task_proxy.h"
+
+#include <memory>
+
+namespace options {
+class Options;
+}
+
+namespace operator_counting {
+class DeleteRelaxationConstraints : public ConstraintGenerator {
+    bool use_time_vars;
+    int use_integer_vars_op, use_integer_vars_facts, use_integer_vars_achiever, use_integer_vars_time;
+
+    // [U_o] Is op part of the relaxed plan? Binary, indexed with op.id.
+    std::vector<int> lp_var_id_op_used;
+    std::vector<int> lp_var_id_op_used2;
+
+    // [R_f] Is fact <V,v> reached by the relaxed plan? Binary, indexed with var.id, value
+    std::vector<std::vector<int>> lp_var_id_fact_reached;
+
+    // [F_{o,f}] Is o the first achiever of fact <V,v> in the relaxed plan? Binary, indexed with op.id, var.id, value
+    std::vector<std::vector<std::vector<int>>> lp_var_id_first_achiever;
+
+    // [T_o] At what time is o used first? {0, ..., |O|}, indexed with op.id
+    std::vector<int> lp_var_id_op_time;
+    std::vector<int> lp_var_id_op_time2;
+
+    // [T_f] At what time is <V,v> first achieved? {0, ..., |O|}, indexed with var.id, value
+    std::vector<std::vector<int>> lp_var_id_fact_time;
+
+    // Indices of constraints that change in every state (indexed with var.id, value)
+    std::vector<std::vector<int>> constraint_ids;
+
+    // The state that is currently used for setting the bounds.
+    // Remembering this makes it faster to unset the bounds when the state changes.
+    std::vector<FactProxy> last_state;
+
+    int get_var_op_used(OperatorProxy op);
+    int get_var_op_used2(OperatorProxy op);
+    int get_var_fact_reached(FactProxy f);
+    int get_var_first_achiever(OperatorProxy op, FactProxy f);
+    int get_var_op_time(OperatorProxy op);
+    int get_var_op_time2(OperatorProxy op);
+    int get_var_fact_time(FactProxy f);
+
+    int get_constraint_id(FactProxy f);
+
+    void create_auxiliary_variables(TaskProxy task_proxy,
+                                    std::vector<lp::LPVariable> &variables);
+    void create_constraints(TaskProxy task_proxy,
+                            std::vector<lp::LPVariable> &variables,
+                            std::vector<lp::LPConstraint> &constraints,
+                            double infinity);
+public:
+    DeleteRelaxationConstraints(const options::Options &opts);
+
+    virtual void initialize_constraints(
+        const std::shared_ptr<AbstractTask> &task,
+        std::vector<lp::LPVariable> &variables,
+        std::vector<lp::LPConstraint> &constraints,
+        double infinity) override;
+    virtual bool update_constraints(
+        const State &state, lp::LPSolver &lp_solver) override;
+};
+}
+
+#endif
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/flow_constraint_internals.cc fast-downward/src/search/operator_counting/flow_constraint_internals.cc
--- fast-downward-original/src/search/operator_counting/flow_constraint_internals.cc	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/flow_constraint_internals.cc	2021-03-18 23:58:06.141479900 -0300
@@ -0,0 +1,242 @@
+#include "flow_constraint_internals.h"
+
+#include "../lp/lp_solver.h"
+#include "../utils/logging.h"
+#include "../utils/memory.h"
+
+using namespace std;
+
+namespace operator_counting {
+FlowConstraintInternals::FlowConstraintInternals(
+    const AbstractTask &task, vector<lp::LPVariable> &variables,
+    vector<lp::LPConstraint> &constraints, double infinity,
+    const FlowConstraintSettings &settings)
+    : initial_state_is_dead_end(false),
+      single_goal_state(-1),
+      abstraction_function(nullptr) {
+    TaskProxy task_proxy(task);
+    auto abstraction_and_ts = pdbs::project_task(
+        task, settings.pattern, settings.remove_dead_states, settings.use_mutexes, settings.partial_merge_states);
+    abstraction_function = utils::make_unique_ptr<pdbs::AbstractionFunction>(move(abstraction_and_ts.first));
+    const pdbs::AbstractTransitionSystem &transition_system = abstraction_and_ts.second;
+    num_abstract_states = transition_system.num_states;
+
+    if (transition_system.goal_states.empty()) {
+        initial_state_is_dead_end = true;
+    } else {
+        create_constraints(variables, constraints, infinity, transition_system, task_proxy, settings);
+    }
+}
+
+
+vector<OperatorCategory> FlowConstraintInternals::get_operator_categories(
+    const pdbs::AbstractTransitionSystem &transition_system, const TaskProxy &task_proxy,
+    const FlowConstraintSettings &settings) {
+    int num_operators = task_proxy.get_operators().size();
+    vector<OperatorCategory> operator_category(num_operators, OperatorCategory::USE_STRONG_LINKING_CONSTRAINT);
+
+    vector<int> num_self_loops(num_operators, 0);
+    for (pdbs::Transition t : transition_system.self_loops) {
+        num_self_loops[t.op_id] += 1;
+    }
+    for (int op_id : transition_system.self_loops_on_all_states) {
+        num_self_loops[op_id] += transition_system.num_states;
+    }
+
+    vector<int> num_state_changing_transitions(num_operators, 0);
+    for (pdbs::Transition t : transition_system.state_changing_transitions) {
+        num_state_changing_transitions[t.op_id] += 1;
+    }
+
+    for (int op_id = 0; op_id < num_operators; ++op_id) {
+        int num_sct = num_state_changing_transitions[op_id];
+        int num_loops = num_self_loops[op_id];
+
+        if (settings.single_transition_optimization && num_sct == 1 && num_loops == 0) {
+            operator_category[op_id] = OperatorCategory::USE_OP_COUNT_DIRECTLY;
+        }
+
+        if (settings.self_loop_optimization && num_sct == 0 && num_loops > 0) {
+            operator_category[op_id] = OperatorCategory::IGNORE_OPERATOR;
+        }
+
+        if (settings.weak_linking_constraints && num_sct > 0 && num_loops > 0) {
+            operator_category[op_id] = OperatorCategory::USE_WEAK_LINKING_CONSTRAINT;
+        }
+    }
+
+    return operator_category;
+}
+
+void FlowConstraintInternals::create_constraints(
+    vector<lp::LPVariable> &variables, vector<lp::LPConstraint> &constraints, double infinity,
+    const pdbs::AbstractTransitionSystem &transition_system, const TaskProxy &task_proxy,
+    const FlowConstraintSettings &settings) {
+    int num_operators = task_proxy.get_operators().size();
+    vector<OperatorCategory> operator_category = get_operator_categories(transition_system, task_proxy, settings);
+
+    /*
+      Create constraints of the type
+           sum_{t \in in(s)} Count_t - sum_{t \in out(s)} Count_t >= -[s is init]     if s is an abstract goal
+           sum_{t \in in(s)} Count_t - sum_{t \in out(s)} Count_t  = -[s is init]     otherwise
+      for all abstract states s. While doing this, we use operator_category to
+        - replace some Count_t (transition-counting variable) by Count_o (operator-counting variable),
+        - ignore other Count_t variables, and
+        - introduce Count_t variables where necessary.
+
+      Where necessary, we also create a linking constraint (weak or strong, depending on operator_category).
+        sum_{t \in trans(o)} Count_t = Count_o (strong)
+        sum_{t \in trans(o), t is no self loop} Count_t <= Count_o (weak)
+    */
+
+    state_constraint_offset = constraints.size();
+    for (int state = 0; state < transition_system.num_states; ++state) {
+        // Handle initial and goal states later.
+        constraints.emplace_back(0, 0);
+    }
+    // Set some state as current, so we don't need a special case for "no current state".
+    int intitial_id = state_constraint_offset + transition_system.initial_state;
+    current_state = transition_system.initial_state;
+    constraints[intitial_id].set_lower_bound(-1);
+    constraints[intitial_id].set_upper_bound(-1);
+
+    // Special case for single goal state for comparability to SEQ on TNF tasks
+    if (transition_system.goal_states.size() == 1) {
+        single_goal_state = transition_system.goal_states[0];
+        int goal_id = state_constraint_offset +  single_goal_state;
+        int bound = constraints[goal_id].get_lower_bound() + 1;
+        constraints[goal_id].set_lower_bound(bound);
+        constraints[goal_id].set_upper_bound(bound);
+    } else {
+        assert(is_goal.empty());
+        is_goal.resize(transition_system.num_states, false);
+        for (int goal : transition_system.goal_states) {
+            is_goal[goal] = true;
+            int goal_id = state_constraint_offset +  goal;
+            constraints[goal_id].set_upper_bound(infinity);
+        }
+    }
+
+    vector<vector<int>> linking_constraint_entries(num_operators);
+    for (pdbs::Transition t: transition_system.state_changing_transitions) {
+        int op_id = t.op_id;
+        OperatorCategory category = operator_category[op_id];
+        if (category == OperatorCategory::IGNORE_OPERATOR) {
+            continue;
+        }
+        int lp_var;
+        if (category == OperatorCategory::USE_OP_COUNT_DIRECTLY) {
+            lp_var = op_id;
+        } else {
+            // Create transition-counting variable
+            lp_var = variables.size();
+            variables.emplace_back(0, infinity, 0, true);
+            linking_constraint_entries[op_id].push_back(lp_var);
+        }
+
+        /* The lp variable occurs with coefficient -1 in the constraint
+           of its source state because it is an outgoing transition. */
+        int source_constraint_id = state_constraint_offset + t.source;
+        constraints[source_constraint_id].insert(lp_var, -1);
+
+        /* The lp variable occurs with coefficient +1 in the constraint
+           of its target state because it is an incoming transition. */
+        int target_constraint_id = state_constraint_offset + t.target;
+        constraints[target_constraint_id].insert(lp_var, 1);
+    }
+    for (pdbs::Transition t: transition_system.self_loops) {
+        // Self-loops cancel out in all constraints except in the strong linking constraint.
+        int op_id = t.op_id;
+        OperatorCategory category = operator_category[op_id];
+        if (category == OperatorCategory::USE_STRONG_LINKING_CONSTRAINT) {
+            // Create transition-counting variable
+            int lp_var = variables.size();
+            variables.emplace_back(0, infinity, 0, true);
+            linking_constraint_entries[op_id].push_back(lp_var);
+        }
+    }
+    for (int op_id: transition_system.self_loops_on_all_states) {
+        // Self-loops cancel out in all constraints except in the strong linking constraint.
+        OperatorCategory category = operator_category[op_id];
+        if (category == OperatorCategory::USE_STRONG_LINKING_CONSTRAINT) {
+            // Create transition-counting variable
+            int lp_var = variables.size();
+            variables.emplace_back(0, infinity, 0, true);
+            linking_constraint_entries[op_id].push_back(lp_var);
+        }
+    }
+
+    // Create linking constraints.
+    for (int op_id = 0; op_id < num_operators; ++op_id) {
+        OperatorCategory category = operator_category[op_id];
+        if (category != OperatorCategory::USE_STRONG_LINKING_CONSTRAINT &&
+            category != OperatorCategory::USE_WEAK_LINKING_CONSTRAINT) {
+            continue;
+        }
+        if (linking_constraint_entries[op_id].empty()) {
+            // Handle constraints without entries in variable bounds.
+            if (category == OperatorCategory::USE_STRONG_LINKING_CONSTRAINT) {
+                variables[op_id].upper_bound = 0;
+            }
+            // No need to handle a weak linking constraint without entries (C_o >= 0).
+        } else {
+            constraints.emplace_back(0, 0);
+            lp::LPConstraint &linking_constraint = constraints.back();
+            if (category == OperatorCategory::USE_WEAK_LINKING_CONSTRAINT) {
+                linking_constraint.set_lower_bound(-infinity);
+            }
+            linking_constraint.insert(op_id, -1);
+            for (int entry : linking_constraint_entries[op_id]) {
+                linking_constraint.insert(entry, 1);
+            }
+        }
+    }
+}
+
+bool FlowConstraintInternals::update_constraints(
+    const State &state, lp::LPSolver &lp_solver) {
+    if (initial_state_is_dead_end) {
+        return true;
+    }
+    int current_id = state_constraint_offset + current_state;
+    int next_state = abstraction_function->get_abstract_state(state);
+    int next_id = state_constraint_offset + next_state;
+
+    if (next_state == -1) {
+        /* This state was pruned from the transition system as a dead state.
+           If it is reachable, it is a dead end. */
+        return true;
+    }
+
+    if (current_id != next_id) {
+        if (single_goal_state > -1) {
+            // Special case for SEQ comparability on TNF tasks
+            int old_bound = 0;
+            if (current_state == single_goal_state) {
+                old_bound = 1;
+            }
+            lp_solver.set_constraint_bounds(current_id, old_bound, old_bound);
+
+            int new_bound = -1;
+            if (next_state == single_goal_state) {
+                new_bound = 0;
+            }
+            lp_solver.set_constraint_bounds(next_id, new_bound, new_bound);
+        } else {
+            if (is_goal[current_state]) {
+                lp_solver.set_constraint_lower_bound(current_id, 0);
+            } else {
+                lp_solver.set_constraint_bounds(current_id, 0, 0);
+            }
+
+            if (is_goal[next_state]) {
+                lp_solver.set_constraint_lower_bound(next_id, -1);
+            } else {
+                lp_solver.set_constraint_bounds(next_id, -1, -1);
+            }
+        }
+        current_state = next_state;
+    }
+    return false;
+}
+}
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/flow_constraint_internals.h fast-downward/src/search/operator_counting/flow_constraint_internals.h
--- fast-downward-original/src/search/operator_counting/flow_constraint_internals.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/flow_constraint_internals.h	2021-03-18 23:58:06.157130500 -0300
@@ -0,0 +1,66 @@
+#ifndef OPERATOR_COUNTING_FLOW_CONSTRAINT_INTERNALS_H
+#define OPERATOR_COUNTING_FLOW_CONSTRAINT_INTERNALS_H
+
+#include "constraint_generator.h"
+
+#include "../pdbs/explicit_projection.h"
+#include "../pdbs/pattern_generator.h"
+
+#include <vector>
+
+namespace options {
+class Options;
+}
+
+namespace operator_counting {
+enum class OperatorCategory {
+    IGNORE_OPERATOR,
+    USE_OP_COUNT_DIRECTLY,
+    USE_WEAK_LINKING_CONSTRAINT,
+    USE_STRONG_LINKING_CONSTRAINT
+};
+
+struct FlowConstraintSettings {
+    pdbs::Pattern pattern;
+    bool remove_dead_states;
+    bool single_transition_optimization;
+    bool self_loop_optimization;
+    bool weak_linking_constraints;
+    bool use_mutexes;
+    std::vector<std::vector<int>> partial_merge_states;
+};
+
+class FlowConstraintInternals {
+    std::vector<bool> is_goal;
+    int state_constraint_offset;
+    int current_state;
+    bool initial_state_is_dead_end;
+    int single_goal_state;
+    std::unique_ptr<pdbs::AbstractionFunction> abstraction_function;
+
+    int num_abstract_states;
+
+    std::vector<OperatorCategory> get_operator_categories(
+        const pdbs::AbstractTransitionSystem &transition_system, const TaskProxy &task_proxy,
+        const FlowConstraintSettings &settings);
+    void create_constraints(
+        std::vector<lp::LPVariable> &variables, std::vector<lp::LPConstraint> &constraints, double infinity,
+        const pdbs::AbstractTransitionSystem &transition_system,
+        const TaskProxy &task_proxy,
+        const FlowConstraintSettings &settings);
+public:
+    FlowConstraintInternals(
+        const AbstractTask &task,
+        std::vector<lp::LPVariable> &variables,
+        std::vector<lp::LPConstraint> &constraints,
+        double infinity,
+        const FlowConstraintSettings &settings);
+
+    bool update_constraints(const State &state, lp::LPSolver &lp_solver);
+    int get_num_abstract_states() const {
+        return num_abstract_states;
+    }
+};
+}
+
+#endif
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/flow_constraints.cc fast-downward/src/search/operator_counting/flow_constraints.cc
--- fast-downward-original/src/search/operator_counting/flow_constraints.cc	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/flow_constraints.cc	2021-03-19 11:03:37.840290800 -0300
@@ -0,0 +1,542 @@
+#include "flow_constraints.h"
+
+#include "../option_parser.h"
+#include "../plugin.h"
+#include "../lp/lp_solver.h"
+#include "../utils/logging.h"
+#include "../utils/timer.h"
+#include "../utils/countdown_timer.h"
+#include "../algorithms/combinations.h"
+
+#include <unordered_map>
+
+using namespace std;
+
+namespace operator_counting {
+
+FlowConstraints::FlowConstraints(const options::Options &opts)
+    : pattern_generator(opts.get<shared_ptr<pdbs::PatternCollectionGenerator>>("patterns")),
+      remove_dead_states(opts.get<bool>("remove_dead_states")),
+      single_transition_optimization(opts.get<bool>("single_transition_optimization")),
+      self_loop_optimization(opts.get<bool>("self_loop_optimization")),
+      weak_linking_constraints(opts.get<bool>("weak_linking_constraints")),
+      use_mutexes(opts.get<bool>("use_mutexes")),
+      partial_merges(opts.get<int>("partial_merges")),
+      max_merge_feature_size(opts.get<int>("max_merge_feature_size")),
+      partial_merge_time_limit(opts.get<double>("partial_merge_time_limit")),
+      lp_solve_time_limit(opts.get<double>("merge_lp_solve_time_limit")),
+      merge_goal_only(opts.get<bool>("merge_goal_only")),
+      merge_preconditions(opts.get<int>("merge_preconditions")),
+      merge_effects(opts.get<int>("merge_effects")){
+}
+
+void FlowConstraints::initialize_constraints(
+    const shared_ptr<AbstractTask> &task,
+    vector<lp::LPVariable> &variables,
+    vector<lp::LPConstraint> &constraints,
+    double infinity) {
+    assert(pattern_generator);
+    pdbs::PatternCollectionInformation pattern_collection_info =
+        pattern_generator->generate(task);
+    shared_ptr<pdbs::PatternCollection> patterns = pattern_collection_info.get_patterns();
+    //pattern_generator = nullptr;
+
+    int num_maximal_abstract_states = 0;
+    int num_actual_abstract_states = 0;
+    TaskProxy task_proxy(*task);
+    VariablesProxy vars = task_proxy.get_variables();
+
+    utils::Timer constraint_generation_timer;
+
+    sub_constraints.reserve(patterns->size());
+    for (const pdbs::Pattern &pattern : *patterns) {
+        FlowConstraintSettings settings;
+        settings.pattern = pattern;
+        settings.remove_dead_states = remove_dead_states;
+        settings.single_transition_optimization = single_transition_optimization;
+        settings.self_loop_optimization = self_loop_optimization;
+        settings.weak_linking_constraints = weak_linking_constraints;
+        settings.use_mutexes = use_mutexes;
+        sub_constraints.emplace_back(*task, variables, constraints, infinity, settings);
+
+        int num_abstract_states = 1;
+        for (int v : pattern) {
+            num_abstract_states *= vars[v].get_domain_size();
+        }
+        num_maximal_abstract_states += num_abstract_states;
+        num_actual_abstract_states += sub_constraints.back().get_num_abstract_states();
+    }
+
+    if (partial_merges == 1) {
+        add_partial_merge_features(*task, variables, constraints, infinity);
+    } else if (partial_merges == 2) {
+        vector<int> all_operators (task->get_num_operators());
+        for (int i = 0; i < task->get_num_operators(); i++)
+            all_operators[i] = i;
+        add_op_merge_features(*task, variables, constraints, all_operators, infinity);
+    } else {
+        add_op_merge_features(*task, variables, constraints, observations, infinity);
+    }
+
+    cout << "Flow constraints abstract states for original patterns: " << num_maximal_abstract_states << endl;
+    cout << "Flow constraints actual abstract states: " << num_actual_abstract_states << endl;
+    cout << "Flow constraints removed abstract states: " << num_maximal_abstract_states - num_actual_abstract_states << endl;
+    cout << "Flow constraints generation time: " << constraint_generation_timer << endl;
+}
+
+struct HashPattern {
+    size_t operator()(const pdbs::Pattern &v) const {
+        size_t key = v.size();
+        for (auto &i : v) {
+            key ^= i + 0x9e3779b9 + (key << 6) + (key >> 2);
+        }
+        return key;
+    }
+};
+
+bool detect_unrepresented_features(const vector<lp::LPVariable> &variables,
+                                   const vector<lp::LPConstraint> &constraints,
+                                   const TaskProxy &task_proxy,
+                                   double lp_solve_time_limit,
+                                   const utils::CountdownTimer &remaining_time,
+                                   vector<int> &operator_handled,
+                                   int feature_size,
+                                   vector<vector<FactPair>> &required_features,
+                                   bool &found_operator_above_feature_size) {
+    // HACK: hard-coded for now.
+#ifdef COIN_HAS_CPX
+    lp::LPSolver lp_solver(lp::LPSolverType::CPLEX);
+#else
+    lp::LPSolver lp_solver(lp::LPSolverType::SOPLEX);
+#endif
+    vector<double> solution;
+    lp_solver.load_problem(lp::LPObjectiveSense::MINIMIZE, variables, constraints);
+    utils::Timer lp_solve_timer;
+    lp_solver.solve();
+    solution = lp_solver.extract_solution();
+    if (lp_solve_timer() > lp_solve_time_limit) {
+        cout << "Solving the LP took " << lp_solve_timer << " which exceeds the time limit of "
+             << lp_solve_time_limit << "s. Stopping feature detection."<< endl;
+        return false;
+    }
+    double EPSILON = 0.001;
+    OperatorsProxy operators = task_proxy.get_operators();
+    VariablesProxy vars = task_proxy.get_variables();
+    int num_variables = vars.size();
+    assert(solution.size() >= operators.size());
+    bool added_feature = false;
+    for (OperatorProxy op : operators) {
+        if (remaining_time.is_expired()) {
+            cout << "Time limit for partial merges exceeded."<< endl;
+            return false;
+        }
+        if (solution[op.get_id()] > EPSILON && operator_handled[op.get_id()] == 0 || operator_handled[op.get_id()] == 2) {
+            vector<int> effect_on_var(num_variables, -1);
+            for (EffectProxy effect : op.get_effects()) {
+                int var = effect.get_fact().get_variable().get_id();
+                effect_on_var[var] = effect.get_fact().get_value();
+            }
+            vector<FactPair> prevail_conditions;
+            vector<FactPair> real_preconditions;
+            vector<FactPair> all_preconditions;
+            for (FactProxy precondition : op.get_preconditions()) {
+                int var = precondition.get_variable().get_id();
+                int pre = precondition.get_value();
+                int post = effect_on_var[var];
+                if (post == -1 || post == pre) {
+                    prevail_conditions.emplace_back(var, pre);
+                    all_preconditions.emplace_back(var, pre);
+                } else {
+                    real_preconditions.emplace_back(var, pre);
+                    all_preconditions.emplace_back(var, pre);
+                }
+            }
+            int num_preconditions = all_preconditions.size();
+            if (num_preconditions > feature_size && !prevail_conditions.empty()) {
+                found_operator_above_feature_size = true;
+            }
+            if (operator_handled[op.get_id()] == 2) {
+                Combinations<FactPair> combos;
+                for (vector<FactPair> feature : combos.get_combinations(all_preconditions, feature_size)) {
+                    sort(feature.begin(), feature.end());
+                    required_features.push_back(feature);
+                    added_feature = true;
+                }
+                operator_handled[op.get_id()] = 1;
+                continue;
+            }
+            for (FactPair prevail : prevail_conditions) {
+                for (FactPair pre : real_preconditions) {
+                    int num_extra_features = min(feature_size - 2, num_preconditions - 2);
+                    Combinations<FactPair> combos;
+                    for (vector<FactPair> feature : combos.get_combinations(all_preconditions, num_extra_features)) {
+                        // HACK: could remove both from all_preconditions before, but meh.
+                        bool useful_feature = true;
+                        for (FactPair f : feature) {
+                            if (f == prevail || f == pre) {
+                                useful_feature = false;
+                                break;
+                            }
+                        }
+                        if (!useful_feature) {
+                            continue;
+                        }
+                        feature.push_back(prevail);
+                        feature.push_back(pre);
+                        sort(feature.begin(), feature.end());
+                        required_features.push_back(feature);
+                        added_feature = true;
+                    }
+                }
+            }
+            operator_handled[op.get_id()] = 1;
+        }
+    }
+    return added_feature;
+}
+
+void FlowConstraints::add_partial_merge_features(
+    const AbstractTask &task,
+    vector<lp::LPVariable> &variables,
+    vector<lp::LPConstraint> &constraints,
+    double infinity) {
+    utils::Timer partial_merge_timer;
+    utils::CountdownTimer partial_merge_remaining_time(partial_merge_time_limit);
+    TaskProxy task_proxy(task);
+
+    int num_base_variables = variables.size();
+    int num_base_constraints = constraints.size();
+    int num_base_sub_constraints = sub_constraints.size();
+
+    int num_iterations = 0;
+    int num_added_features = 0;
+    int feature_size = 2;
+
+    unordered_map<pdbs::Pattern, vector<vector<int>>, HashPattern>
+        represented_features;
+    vector<vector<FactPair>> required_features;
+
+    while (feature_size <= max_merge_feature_size && !partial_merge_remaining_time.is_expired()) {
+        cout << "Partially merging features of size " << feature_size << endl;
+        vector<int> operator_handled(task_proxy.get_operators().size(), 0);
+        for (int id : observations)
+            operator_handled[id] = 2;
+
+        bool found_operator_above_feature_size = false;
+        do {
+            // Search for new features
+            bool added_feature = detect_unrepresented_features(variables, constraints, task_proxy, lp_solve_time_limit,
+                                             partial_merge_remaining_time,
+                                             operator_handled, feature_size, required_features,
+                                             found_operator_above_feature_size);
+            if (!added_feature || partial_merge_remaining_time.is_expired())
+                break;
+
+            ++num_iterations;
+
+            // Remove duplicates
+            for (const vector<FactPair> &feature : required_features) {
+                pdbs::Pattern pattern;
+                vector<int> state;
+                for (FactPair fact : feature) {
+                    pattern.push_back(fact.var);
+                    state.push_back(fact.value);
+                }
+                vector<vector<int>> &represented_pattern_features = represented_features[pattern];
+                if (find(represented_pattern_features.begin(), represented_pattern_features.end(), state) == represented_pattern_features.end()) {
+                    represented_pattern_features.push_back(state);
+                    ++num_added_features;
+                }
+            }
+            required_features.clear();
+
+            // Erase old constraints 
+            variables.erase(variables.begin() + num_base_variables, variables.end());
+            constraints.erase(constraints.begin() + num_base_constraints, constraints.end());
+            sub_constraints.erase(sub_constraints.begin() + num_base_sub_constraints, sub_constraints.end());
+
+            // Add constraints to represented features
+            cout << "Patterns: " << endl;
+            for (const auto &entry : represented_features) {
+                if (partial_merge_remaining_time.is_expired()) {
+                    break;
+                }
+                const pdbs::Pattern &pattern = entry.first;
+                const vector<vector<int>> &states = entry.second;
+                cout << pattern << ": " << states << endl;
+                FlowConstraintSettings settings;
+                settings.pattern = pattern;
+                settings.remove_dead_states = remove_dead_states;
+                settings.single_transition_optimization = single_transition_optimization;
+                settings.self_loop_optimization = self_loop_optimization;
+                settings.weak_linking_constraints = weak_linking_constraints;
+                settings.use_mutexes = use_mutexes;
+                settings.partial_merge_states = states;
+                // Magic done here
+                sub_constraints.emplace_back(task, variables, constraints, infinity, settings);
+            }
+        } while (found_operator_above_feature_size);
+        ++feature_size;
+    }
+
+    cout << "Flow constraints partial merge iterations: " << num_iterations << endl;
+    cout << "Flow constraints partial merge added features: " << num_added_features << endl;
+    cout << "Flow constraints partial merge time: " << partial_merge_timer << endl;
+}
+
+
+void FlowConstraints::add_op_merge_features(
+        const AbstractTask &task,
+        vector<lp::LPVariable> &variables,
+        vector<lp::LPConstraint> &constraints,
+        const vector<int> &operator_ids,
+        double infinity) {
+    TaskProxy task_proxy(task);
+    OperatorsProxy ops = task_proxy.get_operators();
+    FlowConstraintSettings settings;
+    settings.remove_dead_states = remove_dead_states;
+    settings.single_transition_optimization = single_transition_optimization;
+    settings.self_loop_optimization = self_loop_optimization;
+    settings.weak_linking_constraints = weak_linking_constraints;
+    settings.use_mutexes = use_mutexes;
+    unordered_map<pdbs::Pattern, vector<vector<int>>, HashPattern> represented_features;
+
+    vector<bool> goal_vars(task_proxy.get_variables().size(), false);
+    if (merge_goal_only) {
+        for (FactProxy goal : task_proxy.get_goals()) {
+            goal_vars[goal.get_variable().get_id()] = true;
+        }
+    }
+
+    if (merge_preconditions == 1) {
+        // Intra-operator
+        for (int id : operator_ids) {
+            vector<FactPair> all_facts;
+            for (FactProxy pre : ops[id].get_preconditions()) {
+                if (!merge_goal_only || goal_vars[pre.get_variable().get_id()])
+                    all_facts.push_back(pre.get_pair());
+            }
+            if (all_facts.size() >= max_merge_feature_size) {
+                /*sort (all_facts.begin(), all_facts.end(), [](FactPair &a, FactPair &b) {
+                    return a.var < b.var;
+                });*/
+                // Create patterns
+                Combinations<FactPair> combos;
+                for (vector<FactPair> feature : combos.get_combinations(all_facts, max_merge_feature_size)) {
+                    sort(feature.begin(), feature.end());
+                    pdbs::Pattern pattern;
+                    vector<int> state;
+                    for (FactPair fact : feature) {
+                        pattern.push_back(fact.var);
+                        state.push_back(fact.value);
+                    }
+                    vector<vector<int>> &represented_pattern_features = represented_features[pattern];
+                    if (find(represented_pattern_features.begin(), represented_pattern_features.end(), state) == represented_pattern_features.end()) {
+                        represented_pattern_features.push_back(state);
+                    }
+                }
+            }
+        }
+    } else if (merge_preconditions == 2) {
+        // Inter-operator
+        vector<FactPair> all_facts;
+        for (int id : operator_ids) {
+            for (FactProxy pre : ops[id].get_preconditions()) {
+                if (!merge_goal_only || goal_vars[pre.get_variable().get_id()])
+                    all_facts.push_back(pre.get_pair());
+            }
+        }
+        if (all_facts.size() >= max_merge_feature_size) {
+            /*sort (all_facts.begin(), all_facts.end(), [](FactPair &a, FactPair &b) {
+                return a.var < b.var;
+            });*/
+            // Create patterns
+            Combinations<FactPair> combos;
+            for (vector<FactPair> feature : combos.get_combinations(all_facts, max_merge_feature_size)) {
+                sort(feature.begin(), feature.end());
+                pdbs::Pattern pattern;
+                vector<int> state;
+                for (FactPair fact : feature) {
+                    pattern.push_back(fact.var);
+                    state.push_back(fact.value);
+                }
+                vector<vector<int>> &represented_pattern_features = represented_features[pattern];
+                if (find(represented_pattern_features.begin(), represented_pattern_features.end(), state) == represented_pattern_features.end()) {
+                    represented_pattern_features.push_back(state);
+                }
+            }
+        }
+    }
+
+    if (merge_effects == 1) {
+        for (int id : operator_ids) {
+            vector<FactPair> all_facts;
+            for (EffectProxy eff : ops[id].get_effects()) {
+                if (!merge_goal_only || goal_vars[eff.get_fact().get_variable().get_id()])
+                    all_facts.push_back(eff.get_fact().get_pair());
+            }
+            if (all_facts.size() >= max_merge_feature_size) {
+                /*sort (all_facts.begin(), all_facts.end(), [](FactPair &a, FactPair &b) {
+                    return a.var < b.var;
+                });*/
+                // Create patterns
+                Combinations<FactPair> combos;
+                for (vector<FactPair> feature : combos.get_combinations(all_facts, max_merge_feature_size)) {
+                    sort(feature.begin(), feature.end());
+                    pdbs::Pattern pattern;
+                    vector<int> state;
+                    for (FactPair fact : feature) {
+                        pattern.push_back(fact.var);
+                        state.push_back(fact.value);
+                    }
+                    vector<vector<int>> &represented_pattern_features = represented_features[pattern];
+                    if (find(represented_pattern_features.begin(), represented_pattern_features.end(), state) == represented_pattern_features.end()) {
+                        represented_pattern_features.push_back(state);
+                    }
+                }
+            }
+        }
+    } else if (merge_effects == 2) {
+        vector<FactPair> all_facts;
+        for (int id : operator_ids) {
+            for (EffectProxy eff : ops[id].get_effects()) {
+                if (!merge_goal_only || goal_vars[eff.get_fact().get_variable().get_id()])
+                    all_facts.push_back(eff.get_fact().get_pair());
+            }
+        }
+        if (all_facts.size() >= max_merge_feature_size) {
+            /*sort (all_facts.begin(), all_facts.end(), [](FactPair &a, FactPair &b) {
+                return a.var < b.var;
+            });*/
+            // Create patterns
+            Combinations<FactPair> combos;
+            for (vector<FactPair> feature : combos.get_combinations(all_facts, max_merge_feature_size)) {
+                sort(feature.begin(), feature.end());
+                pdbs::Pattern pattern;
+                vector<int> state;
+                for (FactPair fact : feature) {
+                    pattern.push_back(fact.var);
+                    state.push_back(fact.value);
+                }
+                vector<vector<int>> &represented_pattern_features = represented_features[pattern];
+                if (find(represented_pattern_features.begin(), represented_pattern_features.end(), state) == represented_pattern_features.end()) {
+                    represented_pattern_features.push_back(state);
+                }
+            }
+        }
+    }
+
+    // Add constraints to represented features
+    //sub_constraints.reserve(patterns->size());
+    cout << "Paterns: " << endl;
+    for (const auto &entry : represented_features) {
+        const pdbs::Pattern &pattern = entry.first;
+        const vector<vector<int>> &states = entry.second;
+        cout << pattern << ": " << states << endl;
+        FlowConstraintSettings settings;
+        settings.pattern = pattern;
+        settings.remove_dead_states = remove_dead_states;
+        settings.single_transition_optimization = single_transition_optimization;
+        settings.self_loop_optimization = self_loop_optimization;
+        settings.weak_linking_constraints = weak_linking_constraints;
+        settings.use_mutexes = use_mutexes;
+        settings.partial_merge_states = states;
+        // Creates projection
+        sub_constraints.emplace_back(task, variables, constraints, infinity, settings);
+    }
+}
+
+
+bool FlowConstraints::update_constraints(
+    const State &state, lp::LPSolver &lp_solver) {
+    for (FlowConstraintInternals &constraint : sub_constraints) {
+        if (constraint.update_constraints(state, lp_solver)) {
+            return true;
+        }
+    }
+    return false;
+}
+
+static shared_ptr<ConstraintGenerator> _parse(OptionParser &parser) {
+    parser.add_option<shared_ptr<pdbs::PatternCollectionGenerator>>(
+        "patterns",
+        "pattern generation method",
+        "systematic(1)");
+
+    parser.add_option<bool>(
+        "remove_dead_states",
+        "remove unreachable and irrelevant states from all abstractions "
+        "before generating constraints",
+        "true");
+
+    parser.add_option<bool>(
+        "single_transition_optimization",
+        "do not introduce transition-counting variables and linking constraints "
+        "if an operator only induces one transition in an abstraction",
+        "true");
+
+    parser.add_option<bool>(
+        "self_loop_optimization",
+        "do not introduce transition-counting variables and linking constraints "
+        "if an operator only induces self loops in an abstraction",
+        "true");
+
+    parser.add_option<bool>(
+        "weak_linking_constraints",
+        "use weak linking constraints instead of strong linking constraints in cases "
+        "where this does not lead to lower heuristic quality",
+        "true");
+
+    parser.add_option<bool>(
+        "use_mutexes",
+        "remove states from abstract transition systems that violate mutex information",
+        "true");
+
+    parser.add_option<int>(
+        "partial_merges",
+        "incremental detection of partial merges",
+        "1");
+
+    parser.add_option<int>(
+        "max_merge_feature_size",
+        "maximal size of features added with partial merges",
+        "2",
+        Bounds("2", "infinity"));
+
+    parser.add_option<double>(
+        "partial_merge_time_limit",
+        "Stop merging facts after x seconds",
+        "infinity",
+        Bounds("0.0", "infinity"));
+
+    parser.add_option<double>(
+        "merge_lp_solve_time_limit",
+        "Stop merging facts if solving the LP once takes more than x seconds",
+        "infinity",
+        Bounds("0.0", "infinity"));
+
+    parser.add_option<bool>(
+        "merge_goal_only",
+        "Include only variables that are mentioned in the goal",
+        "false");
+
+    parser.add_option<int>(
+        "merge_preconditions",
+        "Include features mentioned in preconditions",
+        "0",
+        Bounds("0", "2"));
+
+    parser.add_option<int>(
+        "merge_effects",
+        "Include features mentioned in effects",
+        "0",
+        Bounds("0", "2"));
+
+    Options opts = parser.parse();
+    if (parser.dry_run())
+        return nullptr;
+    return make_shared<FlowConstraints>(opts);
+}
+
+static Plugin<ConstraintGenerator> _plugin("flow_constraints", _parse);
+}
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/flow_constraints.h fast-downward/src/search/operator_counting/flow_constraints.h
--- fast-downward-original/src/search/operator_counting/flow_constraints.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/flow_constraints.h	2021-03-18 23:58:06.157130500 -0300
@@ -0,0 +1,58 @@
+#ifndef OPERATOR_COUNTING_FLOW_CONSTRAINTS_H
+#define OPERATOR_COUNTING_FLOW_CONSTRAINTS_H
+
+#include "constraint_generator.h"
+#include "flow_constraint_internals.h"
+
+#include "../pdbs/pattern_generator.h"
+
+#include <vector>
+
+namespace options {
+class Options;
+}
+
+namespace operator_counting {
+class FlowConstraints : public ConstraintGenerator {
+    std::shared_ptr<pdbs::PatternCollectionGenerator> pattern_generator;
+    bool remove_dead_states;
+    bool single_transition_optimization;
+    bool self_loop_optimization;
+    bool weak_linking_constraints;
+    bool use_mutexes;
+
+    int partial_merges;
+    int max_merge_feature_size;
+    double partial_merge_time_limit;
+    double lp_solve_time_limit;
+
+    bool merge_goal_only;
+    int merge_preconditions;
+    int merge_effects;
+
+    std::vector<FlowConstraintInternals> sub_constraints;
+    void add_partial_merge_features(
+        const AbstractTask &task,
+        std::vector<lp::LPVariable> &variables,
+        std::vector<lp::LPConstraint> &constraints,
+        double infinity);
+    void add_op_merge_features(
+        const AbstractTask &task,
+        std::vector<lp::LPVariable> &variables,
+        std::vector<lp::LPConstraint> &constraints,
+        const std::vector<int> &operator_ids,
+        double infinity);
+public:
+    explicit FlowConstraints(const options::Options &opts);
+
+    virtual void initialize_constraints(
+        const std::shared_ptr<AbstractTask> &task,
+        std::vector<lp::LPVariable> &variables,
+        std::vector<lp::LPConstraint> &constraints,
+        double infinity) override;
+    virtual bool update_constraints(
+        const State &state, lp::LPSolver &lp_solver) override;
+};
+}
+
+#endif
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/lm_cut_constraints.cc fast-downward/src/search/operator_counting/lm_cut_constraints.cc
--- fast-downward-original/src/search/operator_counting/lm_cut_constraints.cc	2020-10-26 22:55:33.066597400 -0300
+++ fast-downward/src/search/operator_counting/lm_cut_constraints.cc	2021-03-25 22:23:59.832444100 -0300
@@ -15,37 +15,107 @@
 using namespace std;
 
 namespace operator_counting {
-void LMCutConstraints::initialize_constraints(
-    const shared_ptr<AbstractTask> &task, vector<lp::LPConstraint> & /*constraints*/,
-    double /*infinity*/) {
-    TaskProxy task_proxy(*task);
-    landmark_generator =
-        utils::make_unique_ptr<lm_cut_heuristic::LandmarkCutLandmarks>(task_proxy);
+
+LMCutConstraints::LMCutConstraints(const options::Options &opts)
+    : noisy(opts.get<int>("noisy")) {
 }
 
+void LMCutConstraints::initialize_constraints( const shared_ptr<AbstractTask> & task, 
+    vector<lp::LPVariable> & variables, vector<lp::LPConstraint> & /*constraints*/, double /*infinity*/) {
+    TaskProxy task_proxy(*task);
+    landmark_generator = utils::make_unique_ptr<lm_cut_heuristic::LandmarkCutLandmarks>(task_proxy);
+    sort(observations.begin(), observations.end());
+    if (noisy == 2) {
+        // Use B variables
+        b_vars.clear();
+        int last_id = -1;
+        for (int obs_id : observations) {
+            if (obs_id == last_id)
+                continue;
+            last_id = obs_id;
+            b_vars[obs_id] = variables.size();
+            variables.emplace_back(0, 1, 0, true);
+        }
+    }
+}
 
 bool LMCutConstraints::update_constraints(const State &state,
                                           lp::LPSolver &lp_solver) {
     assert(landmark_generator);
     vector<lp::LPConstraint> constraints;
     double infinity = lp_solver.get_infinity();
-
+    TaskProxy task_proxy = state.get_task();
+    
+    // Basic landmarks
     bool dead_end = landmark_generator->compute_landmarks(
         state, nullptr,
         [&](const vector<int> &op_ids, int /*cost*/) {
+            cout << "Landmarks: " << endl;
             constraints.emplace_back(1.0, infinity);
             lp::LPConstraint &landmark_constraint = constraints.back();
             for (int op_id : op_ids) {
+                cout << op_id << " - " << task_proxy.get_operators()[op_id].get_name() << endl;
                 landmark_constraint.insert(op_id, 1.0);
             }
         });
-
-    if (dead_end) {
+    if (dead_end)
         return true;
-    } else {
-        lp_solver.add_temporary_constraints(constraints);
-        return false;
+
+    // Get occurrences of each observtion
+    unordered_map<int, int> occur;
+    for (int obs_id : observations)
+        occur[obs_id]++;
+    int last_id = -1; // Last obs_id
+    int var_id = task_proxy.get_operators().size(); // Y_obs
+
+    for (int obs_id : observations) {
+
+        // Ignore duplicates
+        if (obs_id == last_id)
+            continue;
+        last_id = obs_id;
+
+        {
+            // Change goal
+            vector<int> obs;
+            obs.push_back(obs_id);
+            landmark_generator = utils::make_unique_ptr<lm_cut_heuristic::LandmarkCutLandmarks>(task_proxy, obs);
+        }
+
+        dead_end = landmark_generator->compute_landmarks(
+            state, nullptr,
+            [&](const vector<int> &op_ids, int /*cost*/) {
+                cout << "Landmarks: " << endl;
+                if (noisy == 0) {
+                    // Default: >= 1
+                    constraints.emplace_back(1.0, infinity);
+                } else {
+                    constraints.emplace_back(0, infinity);
+                    if (noisy == 1) { // Divide: >= Y_obs / occur(obs)
+                        constraints.back().insert(var_id, -1.0/occur[obs_id]);
+                    } else { // B var: >= B_obs
+                        constraints.back().insert(b_vars[obs_id], -1.0);
+                    }
+                }
+                lp::LPConstraint &landmark_constraint = constraints.back();
+                for (int op_id : op_ids) {
+                    cout << op_id << " - " << task_proxy.get_operators()[op_id].get_name() << endl;
+                    landmark_constraint.insert(op_id, 1.0);
+                }
+            });
+        if (noisy == 2) {
+            // 0 <= B_obs * M - Y_obs
+            constraints.emplace_back(0, infinity);
+            constraints.back().insert(var_id, -1.0);
+            constraints.back().insert(b_vars[obs_id], occur[obs_id] + 1.0);
+        }
+        if (dead_end)
+            return true;
+        var_id++;
     }
+
+    lp_solver.add_temporary_constraints(constraints);
+    return false;
 }
 
 static shared_ptr<ConstraintGenerator> _parse(OptionParser &parser) {
@@ -74,10 +144,11 @@
             "2268-2274",
             "AAAI Press",
             "2013"));
-
+    parser.add_option<int>("noisy", "0 to default approach, 1 to divide landmark minimum, 2 to use B variables", "0");
+    Options opts = parser.parse();
     if (parser.dry_run())
         return nullptr;
-    return make_shared<LMCutConstraints>();
+    return make_shared<LMCutConstraints>(opts);
 }
 
 static Plugin<ConstraintGenerator> _plugin("lmcut_constraints", _parse);
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/lm_cut_constraints.h fast-downward/src/search/operator_counting/lm_cut_constraints.h
--- fast-downward-original/src/search/operator_counting/lm_cut_constraints.h	2020-10-26 22:55:33.069747000 -0300
+++ fast-downward/src/search/operator_counting/lm_cut_constraints.h	2021-03-25 19:05:18.061663500 -0300
@@ -4,6 +4,7 @@
 #include "constraint_generator.h"
 
 #include <memory>
+#include <unordered_map>
 
 namespace lm_cut_heuristic {
 class LandmarkCutLandmarks;
@@ -12,9 +13,13 @@
 namespace operator_counting {
 class LMCutConstraints : public ConstraintGenerator {
     std::unique_ptr<lm_cut_heuristic::LandmarkCutLandmarks> landmark_generator;
+    std::unordered_map<int, int> b_vars;
+    int noisy;
 public:
+	explicit LMCutConstraints(const options::Options &opts);
     virtual void initialize_constraints(
         const std::shared_ptr<AbstractTask> &task,
+        std::vector<lp::LPVariable> & variables,
         std::vector<lp::LPConstraint> &constraints,
         double infinity) override;
     virtual bool update_constraints(const State &state,
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/oc_single_shot_heuristic.cc fast-downward/src/search/operator_counting/oc_single_shot_heuristic.cc
--- fast-downward-original/src/search/operator_counting/oc_single_shot_heuristic.cc	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/oc_single_shot_heuristic.cc	2021-03-25 19:43:29.124847700 -0300
@@ -0,0 +1,499 @@
+#include "oc_single_shot_heuristic.h"
+
+#include "constraint_generator.h"
+
+#include "../option_parser.h"
+#include "../plugin.h"
+
+#include "../utils/markup.h"
+
+#include <cmath>
+#include <fstream>
+#include <algorithm>
+#include <cctype>
+#include <locale>
+
+using namespace std;
+
+// trim from start (in place)
+static inline void ltrim(std::string &s) {
+    s.erase(s.begin(), std::find_if(s.begin(), s.end(), [](int ch) {
+        return !std::isspace(ch);
+    }));
+}
+
+// trim from end (in place)
+static inline void rtrim(std::string &s) {
+    s.erase(std::find_if(s.rbegin(), s.rend(), [](int ch) {
+        return !std::isspace(ch);
+    }).base(), s.end());
+}
+
+// trim from both ends (in place)
+static inline void trim(std::string &s) {
+    ltrim(s);
+    rtrim(s);
+}
+
+using namespace std;
+
+namespace operator_counting {
+
+utils::Timer lp_timer;
+
+OCSingleShotHeuristic::OCSingleShotHeuristic(const Options &opts)
+    : Heuristic(opts),
+      constraint_generators(
+          opts.get_list<shared_ptr<ConstraintGenerator>>("constraint_generators")),
+      lp_h(opts.get<lp::LPSolverType>("lpsolver"), true),
+      lp_h_c(opts.get<lp::LPSolverType>("lpsolver"), true),
+      lp_h_s(opts.get<lp::LPSolverType>("lpsolver"), true),
+      calculate_h(opts.get<bool>("calculate_h")),
+      calculate_h_c(opts.get<bool>("calculate_h_c")),
+      calculate_h_s(opts.get<bool>("calculate_h_s")),
+      filter(opts.get<int>("filter")),
+      h_obs(opts.get<int>("h_obs")),
+      mip(opts.get<bool>("mip")),
+      soft_weight(opts.get<int>("weights")) {
+    // Initialize map to convert operator name to operator ID
+    map_operators(true);
+    // Read observations from file and prune invalid
+    load_observations();
+    prune_observations();
+    // Start timer
+    lp_timer.reset();
+    lp_timer.resume();
+}
+
+void OCSingleShotHeuristic::add_observation_variables(vector<lp::LPVariable> &variables, vector<lp::LPConstraint> &constraints) {
+    // Create observation variables
+    vector<string> obs;
+    for (auto entry : valid_obs_occurrences)
+        obs.push_back(entry.first);
+    sort(obs.begin(), obs.end(), [&](string &a, string &b) {
+            return (op_indexes[a] < op_indexes[b]);
+        });
+    double infinity = lp_h.get_infinity();
+    for (string &op : obs) {
+        // Determine how many times the same observed operation occurs.
+        int count_obs = valid_obs_occurrences[op];
+        cout << "constraint " << op << ": " << std::to_string(op_indexes[op]) << endl;
+        int var_id = variables.size();
+        variables.push_back(lp::LPVariable(0, count_obs, -weights[op], mip));
+        lp::LPConstraint lt_y(0, infinity);
+        lt_y.insert(op_indexes[op], 1);
+        lt_y.insert(var_id, -1);
+        constraints.push_back(lt_y);
+    }
+}
+
+void OCSingleShotHeuristic::add_observation_hard_constraint(vector<lp::LPVariable> &variables, vector<lp::LPConstraint> &constraints) {
+    double infinity = lp_h.get_infinity();
+    int filter = (int)(this->filter * 0.1 * observations.size());
+    int k = max(0, filter - num_pruned_observations);
+    lp::LPConstraint constraint(num_valid_observations - k, infinity);
+    int var_offset = task_proxy.get_operators().size(); 
+    for (uint i = 0; i < valid_obs_occurrences.size(); i++) {
+        constraint.insert(var_offset + i, 1);
+        variables[var_offset + i].objective_coefficient = 0;
+    }
+    constraints.push_back(constraint);
+}
+
+void OCSingleShotHeuristic::set_variable_weights() {
+    if (soft_weight == 1) {
+        double weight_per_op = 1.0 / 1000;
+        for (auto it = observations.begin(); it != observations.end(); ++it)
+            if (op_indexes.find(*it) != op_indexes.end())
+                weights[*it] = weight_per_op;
+    } else if (soft_weight == 2) {
+        double weight_per_op = 1.0;
+        for (auto it = observations.begin(); it != observations.end(); ++it)
+            if (op_indexes.find(*it) != op_indexes.end())
+                weights[*it] = weight_per_op;
+    } else if (soft_weight == 3) {
+        double weight_per_op = 1.0;
+        double weight = weight_per_op;
+        for (auto it = observations.begin(); it != observations.end(); ++it) {
+            if (op_indexes.find(*it) != op_indexes.end()) {
+                max_weight += weight;
+                weights[*it] += weight;
+                weight += weight_per_op;
+            }
+        }
+        for (auto it = obs_occurrences.begin(); it != obs_occurrences.end(); ++it)
+            weights[it->first] /= it->second;
+    }
+}
+
+void OCSingleShotHeuristic::map_operators(bool show) {
+    if (show) {
+        cout << endl << string(80, '*') << endl;
+        cout << "# Mapping X -> op: " << endl;
+    }
+    int i = 0;
+    for (OperatorProxy op : task_proxy.get_operators()) {
+        // Caching operator variable indexes
+        std::string op_name (op.get_name());
+        for (size_t i = 0; i< op.get_name().size(); ++i) {
+            op_name[i] = tolower(op_name.c_str()[i]);
+        }
+        op_indexes[op_name] = i;
+        if (show) {
+            cout << "["<< op_name<< "]: " << op_indexes[op_name] << endl;
+        }
+        i++;
+    }
+    if (show) {
+        cout << string(80, '*') << endl;
+    }
+}
+
+void OCSingleShotHeuristic::show_variables_and_objective(const vector<lp::LPVariable> &variables) {
+    cout << endl << string(80, '*') << endl;
+    cout << "# Variables(" << variables.size() << "): " << endl;
+    for (int i = 0; i < (int) variables.size(); ++i) {
+        cout << "X[" << i << "] = Variable('X_" << i << "'";
+        cout << ", lb=" << variables[i].lower_bound;
+        cout << ", ub=" << variables[i].upper_bound;
+        cout << ", cost[" << i << "] = " << variables[i].objective_coefficient << endl;
+    }
+    cout << string(80, '*') << endl;
+    cout << endl << string(80, '*') << endl;
+    cout << "# Objective function: " << endl;
+    cout << "obj = Objective(";
+    for (int i = 0; i < (int) variables.size(); ++i) {
+        cout << "cost[" << i << "] * X[" << i << "]";
+        if (i < (int) variables.size() - 1) {
+            cout << " + ";
+        }
+    }
+    cout << ", direction='min')" << endl;
+    cout << string(80, '*') << endl;
+}
+
+void OCSingleShotHeuristic::load_observations() {
+    // Read observations from file
+    cout << endl << string(80, '*') << endl;
+    cout << std::endl << "Load observations" << std::endl;
+    ifstream obs_file;
+    obs_file.open("obs.dat");
+    if(obs_file.is_open()){
+        while(!obs_file.eof()) {
+            string obs;
+            getline(obs_file, obs);
+            trim(obs);
+            if(!obs.empty() && obs[0]!=';') {
+                obs = obs.substr(1,obs.length()-2);
+                std::string obs_name (obs);
+                for (size_t i = 0; i< obs.size(); ++i) {
+                    obs_name[i] = tolower(obs.c_str()[i]);
+                }
+                cout << "Observation: " << obs_name << endl;
+                observations.push_back(obs_name);
+            }
+        }
+    }
+    cout << endl << string(80, '*') << endl;
+    obs_file.close();
+    // =-=-=-=-= Each observation is associated with its number of occurrences. =-=-=-=-= //
+    obs_occurrences.clear();
+    for(auto it = observations.begin() ; it != observations.end(); ++it) {
+        obs_occurrences[*it]++;
+    }
+}
+
+void OCSingleShotHeuristic::prune_observations() { 
+    // Debugging output (cumulative: appends new info with each call)
+    std::fstream outfile("debug/observation_sanity.txt", std::ios::out|std::ios::app) ;
+    // Set output stream (set to std::cout to print to terminal)
+    std::ostream& outstream = outfile;
+    // Reinitialize class variables for invalid (unmapped) observations.
+    num_pruned_observations = 0;
+    pruned_observations.clear();
+    valid_obs_occurrences.clear();
+    vector<string> invalid_operators;
+    int num_invalid_operators = 0;
+    //outstream << endl << string(80, '*') << endl;
+    //outstream << "Enforcing observation constraints" << std::endl;
+    outstream << endl<< "-+-"; // marks start
+    for (auto it = obs_occurrences.begin(); it != obs_occurrences.end(); ++it) {
+        // Observation is mappable?
+        // If not: ignore observation, storing it in a separate list.
+        if (op_indexes.find(it->first) == op_indexes.end()) {
+            //outstream << "[INVALID OP] " << op << endl;
+            invalid_operators.push_back(it->first);
+            num_invalid_operators += 1;
+            num_pruned_observations += it->second;
+        } else {
+            valid_obs_occurrences[it->first] = it->second;
+            num_valid_observations += it->second;
+        }
+    }
+    // =-=-=-=-= Report on pruned and invalid operators/observations. =-=-=-=-= //
+    // Basic structure:
+    // Print invalid observations, number of operators and total number of observations.
+    // Last line holds number of observations and number of invalid observations,
+    //  followed by any relevant tags.
+    for (int i = 0 ; i < num_invalid_operators; i++) {
+        outstream << endl<< "[INVALID OP] " << invalid_operators[i] << ": " << obs_occurrences[invalid_operators[i]] <<" time(s).";
+    }
+    if (num_pruned_observations > 0) {
+        outstream << endl << "# mappable operators: " << op_indexes.size() << endl;
+        outstream << "Obs - Total: " << observations.size() << " | Invalid: " << num_pruned_observations;
+    }
+    outfile.flush();
+    outfile.close();
+}
+
+int OCSingleShotHeuristic::compute_heuristic(const GlobalState &global_state) {
+    State state = convert_global_state(global_state);
+    return compute_heuristic(state);
+}
+
+int OCSingleShotHeuristic::compute_heuristic(const State &state) {
+    // Results
+    double result, result_c, result_s;
+    result = result_c = result_s = 0 / 0;
+
+    // Constraints
+    double infinity = lp_h.get_infinity();
+    vector<lp::LPConstraint> constraints;
+    lp::LPConstraint dummy_constraint(0, infinity);
+    dummy_constraint.insert(0, 1); // Hack to make setInteger work.
+    constraints.push_back(dummy_constraint);
+
+    // Create operator variables
+    vector<lp::LPVariable> variables;
+    for (OperatorProxy op : task_proxy.get_operators()) {
+        variables.push_back(lp::LPVariable(0, infinity, op.get_cost(), mip));
+    }
+
+    // Compute LP problem without observation constraints
+    if (calculate_h) {
+        // Initialize LP
+        for (const auto &generator : constraint_generators)
+            generator->initialize_constraints(task, variables, constraints, infinity);
+        cout << "h #constraints: " << constraints.size() << endl;
+        lp_h.load_problem(lp::LPObjectiveSense::MINIMIZE, variables, constraints);
+        cout << "Loaded basic problem." << endl;
+        // Update constraints
+        for (const auto &generator : constraint_generators) {
+            if (generator->update_constraints(state, lp_h)) {
+                calculate_h = false;
+                break;
+            }
+        }
+        // Compute result
+        if (calculate_h) {
+            lp_h.solve();
+            if (lp_h.has_optimal_solution()) {
+                double epsilon = 0.01;
+                double objective_value = lp_h.get_objective_value();
+                result = ceil(objective_value - epsilon);
+            }
+        }
+        cout << "h: " << result << endl;
+    }
+
+    set_variable_weights();
+    if (h_obs) {
+        constraints.clear();
+        constraints.push_back(dummy_constraint);
+        variables.erase(variables.begin() + task_proxy.get_operators().size(), variables.end());
+        add_observation_variables(variables, constraints);
+        // Re-initialize constraints using observations
+        vector<int> observation_ids;
+        for (const string &obs : observations)
+            if (op_indexes.find(obs) != op_indexes.end())
+                observation_ids.push_back(op_indexes[obs]);
+        for (const auto &generator : constraint_generators) {
+            generator->set_observations(observation_ids, h_obs);
+            generator->initialize_constraints(task, variables, constraints, infinity);
+        }
+    } else {
+        add_observation_variables(variables, constraints);
+        // If not initialized already
+        if (calculate_h)
+            for (const auto &generator : constraint_generators)
+                generator->initialize_constraints(task, variables, constraints, infinity);
+    }
+
+    // Compute LP problem with soft observation constraints
+    if (calculate_h_s) {
+        // Initialize LP
+        cout << "h_s #constraints: " << constraints.size() << endl;
+        lp_h_s.load_problem(lp::LPObjectiveSense::MINIMIZE, variables, constraints);
+        cout << "Loaded problem with soft constraints." << endl;
+        // Update constraints
+        for (const auto &generator : constraint_generators) {
+            if (generator->update_constraints(state, lp_h_s))
+                calculate_h_s = false;
+        }
+        // Compute result
+        if (calculate_h_s) {
+            lp_h_s.solve();
+            if (lp_h_s.has_optimal_solution()) {
+                double epsilon = 0.01;
+                double objective_value = lp_h_s.get_objective_value();
+                result_s = ceil(objective_value - epsilon) + max_weight;
+            }
+        }
+        cout << "h_s: " << result_s << endl;
+    }
+    
+    // Compute LP problem with hard observation constraints
+    if (calculate_h_c) {
+        add_observation_hard_constraint(variables, constraints);
+        cout << "h_c #constraints: " << constraints.size() << endl;
+        lp_h_c.load_problem(lp::LPObjectiveSense::MINIMIZE, variables, constraints);
+        cout << "Loaded problem with hard constraints." << endl;
+        // Update constraints
+        for (const auto &generator : constraint_generators) {
+            if (generator->update_constraints(state, lp_h_c))
+                calculate_h_c = false;
+        }
+        // Compute LP
+        if (calculate_h_c) {
+            lp_h_c.solve();
+            if (lp_h_c.has_optimal_solution()) {
+                double epsilon = 0.01;
+                double objective_value = lp_h_c.get_objective_value();
+                result_c = ceil(objective_value - epsilon);
+            }
+        }
+        cout << "h_c: " << result_c << endl;
+    }
+
+    lp_timer.stop();
+    output_results(result, result_c, result_s);
+
+    exit(EXIT_SUCCESS);
+    return 0;
+}
+
+void OCSingleShotHeuristic::output_results(double result, double result_c, double result_s) {
+    // Log solutions
+    cout << "Writing solutions..." << endl;
+    cout << endl << string(80, '*') << endl;
+    vector<double> solution;
+    int num_vars, num_const;
+    if (calculate_h_s) {
+        solution = lp_h_s.extract_solution();
+        num_vars = lp_h_s.get_num_variables();
+        num_const = lp_h_s.get_num_constraints();
+    } else if (calculate_h_c) {
+        solution = lp_h_c.extract_solution();
+        num_vars = lp_h_c.get_num_variables();
+        num_const = lp_h_c.get_num_constraints();
+    } else {
+        solution = lp_h.extract_solution();
+        num_vars = lp_h.get_num_variables();
+        num_const = lp_h.get_num_constraints();
+    }
+    for (int i = 0; i < (int) solution.size(); ++i) {
+        cout << "X[" << i << "] = " << solution[i] << endl;
+    }
+    // Get hits/misses
+    double obs_hits = 0, obs_miss = 0;
+    unordered_map<string, double> counts;
+    for(auto it = observations.begin() ; it != observations.end(); ++it) {
+        if (op_indexes.find(*it) != op_indexes.end()) {
+            if (solution[op_indexes[*it]] > counts[*it]) {
+                obs_hits++;
+                counts[*it]++;
+            } else {
+                obs_miss++;
+            }
+        }
+    }
+    cout << "obs-report: " << observations.size() << " " << num_pruned_observations << " " << obs_hits << " " << obs_miss << endl;
+    cout << "time-report: " << lp_timer << endl;
+    cout << "h-values: " << result << " " << result_c << " " << result_s << endl;
+    cout << string(80, '*') << endl << endl;
+    // Write result
+    cout << "Writing results...";
+    ofstream results;
+    results.open("ocsingleshot_heuristic_result.dat");
+    results << "obs-report: " << observations.size() << " " << num_pruned_observations << " " << obs_hits << " " << obs_miss << endl;
+    results << "time-report: " << lp_timer << endl;
+    results << "h-values: " << result << " " << result_c << " " << result_s << endl;
+    results << "lp-size: " <<  num_vars << " " << num_const << endl;
+    // Write counts
+    int var_i = 0;
+    for (OperatorProxy op : task_proxy.get_operators()) {
+        if (solution[var_i] > 0) {
+            results << "(" << op.get_name() << ") = " << solution[var_i] << endl;
+        }
+        var_i++;
+    }
+    results.flush();
+    results.close();
+    cout << "Done!" << endl;
+}
+
+OCSingleShotHeuristic::~OCSingleShotHeuristic() {
+}
+
+static shared_ptr<Heuristic> _parse(OptionParser &parser) {
+    parser.document_synopsis(
+        "Operator counting heuristic",
+        "An operator counting heuristic computes a linear program (LP) in each "
+        "state. The LP has one variable Count_o for each operator o that "
+        "represents how often the operator is used in a plan. Operator "
+        "counting constraints are linear constraints over these varaibles that "
+        "are guaranteed to have a solution with Count_o = occurrences(o, pi) "
+        "for every plan pi. Minimizing the total cost of operators subject to "
+        "some operator counting constraints is an admissible heuristic. "
+        "For details, see" + utils::format_conference_reference( // TODO - Change this for our paper
+            {"Florian Pommerening", "Gabriele Roeger", "Malte Helmert",
+             "Blai Bonet"},
+            "LP-based Heuristics for Cost-optimal Planning",
+            "http://www.aaai.org/ocs/index.php/ICAPS/ICAPS14/paper/view/7892/8031",
+            "Proceedings of the Twenty-Fourth International Conference"
+            " on Automated Planning and Scheduling (ICAPS 2014)",
+            "226-234",
+            "AAAI Press",
+            "2014"));
+
+    parser.document_language_support("action costs", "supported");
+    parser.document_language_support(
+        "conditional effects",
+        "not supported (the heuristic supports them in theory, but none of "
+        "the currently implemented constraint generators do)");
+    parser.document_language_support(
+        "axioms",
+        "not supported (the heuristic supports them in theory, but none of "
+        "the currently implemented constraint generators do)");
+    parser.document_property("admissible", "yes");
+    parser.document_property(
+        "consistent",
+        "yes, if all constraint generators represent consistent heuristics");
+    parser.document_property("safe", "yes");
+    // TODO: prefer operators that are non-zero in the solution.
+    parser.document_property("preferred operators", "no");
+
+    parser.add_list_option<shared_ptr<ConstraintGenerator>>(
+        "constraint_generators",
+        "methods that generate constraints over operator counting variables");
+    parser.add_option<bool>("calculate_h", "calculate h-value", "false");
+    parser.add_option<bool>("calculate_h_c", "calculate h-value with hard observation constraints", "true");
+    parser.add_option<bool>("calculate_h_s", "calculate h-value with soft observation constraints", "false");
+    parser.add_option<int>("weights", "weight type for soft constraints", "0");
+    parser.add_option<int>("filter", "observation filter", "0");
+    parser.add_option<int>("h_obs", "enable observations inside heuristic constraints", "0");
+    parser.add_option<bool>("mip", "use MIP solver", "false");
+    lp::add_lp_solver_option_to_parser(parser);
+    Heuristic::add_options_to_parser(parser);
+    Options opts = parser.parse();
+    if (parser.help_mode())
+        return nullptr;
+    opts.verify_list_non_empty<shared_ptr<ConstraintGenerator>>(
+        "constraint_generators");
+    if (parser.dry_run())
+        return nullptr;
+    return make_shared<OCSingleShotHeuristic>(opts);
+}
+
+static Plugin<Evaluator> _plugin("ocsingleshot", _parse);
+}
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/oc_single_shot_heuristic.h fast-downward/src/search/operator_counting/oc_single_shot_heuristic.h
--- fast-downward-original/src/search/operator_counting/oc_single_shot_heuristic.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/operator_counting/oc_single_shot_heuristic.h	2021-03-18 23:58:06.188373600 -0300
@@ -0,0 +1,59 @@
+#ifndef OPERATOR_COUNTING_OPERATOR_COUNTING_HEURISTIC_H
+#define OPERATOR_COUNTING_OPERATOR_COUNTING_HEURISTIC_H
+
+#include "../heuristic.h"
+
+#include "../lp/lp_solver.h"
+
+#include <memory>
+#include <vector>
+#include <string>
+#include <unordered_map>
+
+namespace options {
+class Options;
+}
+
+namespace operator_counting {
+class ConstraintGenerator;
+
+class OCSingleShotHeuristic : public Heuristic {
+    std::vector<std::shared_ptr<ConstraintGenerator>> constraint_generators;
+    lp::LPSolver lp_h;
+    lp::LPSolver lp_h_c;
+    lp::LPSolver lp_h_s;
+    bool calculate_h, calculate_h_c, calculate_h_s;
+    int filter;
+    int h_obs;
+    bool mip;
+
+    std::unordered_map<std::string,int> op_indexes;
+    std::vector<std::string> observations;
+    std::vector<std::string> pruned_observations;
+    std::unordered_map<std::string, int> obs_occurrences;
+    std::unordered_map<std::string, int> valid_obs_occurrences;
+    int num_pruned_observations = 0;
+    int num_valid_observations = 0;
+
+    int soft_weight;
+    std::unordered_map<std::string, double> weights;
+    double max_weight = 0;
+
+protected:
+    virtual int compute_heuristic(const GlobalState &global_state) override;
+    int compute_heuristic(const State &state);
+    void load_observations();
+    void prune_observations();
+    void add_observation_variables(std::vector<lp::LPVariable> &variables, std::vector<lp::LPConstraint> &constraints);
+    void add_observation_hard_constraint(std::vector<lp::LPVariable> &variables, std::vector<lp::LPConstraint> &constraints);
+    void set_variable_weights();
+    void output_results(double result, double result_c, double result_s);
+public:
+    explicit OCSingleShotHeuristic(const options::Options &opts);
+    ~OCSingleShotHeuristic();
+    void map_operators(bool show = false);
+    void show_variables_and_objective(const std::vector<lp::LPVariable> &variables);
+};
+}
+
+#endif
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/operator_counting_heuristic.cc fast-downward/src/search/operator_counting/operator_counting_heuristic.cc
--- fast-downward-original/src/search/operator_counting/operator_counting_heuristic.cc	2020-10-26 22:55:33.073739400 -0300
+++ fast-downward/src/search/operator_counting/operator_counting_heuristic.cc	2021-03-18 23:58:06.188373600 -0300
@@ -25,7 +25,7 @@
     }
     vector<lp::LPConstraint> constraints;
     for (const auto &generator : constraint_generators) {
-        generator->initialize_constraints(task, constraints, infinity);
+        generator->initialize_constraints(task, variables, constraints, infinity);
     }
     lp_solver.load_problem(lp::LPObjectiveSense::MINIMIZE, variables, constraints);
 }
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/pho_constraints.cc fast-downward/src/search/operator_counting/pho_constraints.cc
--- fast-downward-original/src/search/operator_counting/pho_constraints.cc	2020-10-26 22:55:33.078752500 -0300
+++ fast-downward/src/search/operator_counting/pho_constraints.cc	2021-03-18 23:58:06.188373600 -0300
@@ -25,6 +25,7 @@
 
 void PhOConstraints::initialize_constraints(
     const shared_ptr<AbstractTask> &task,
+    vector<lp::LPVariable> & /*variables*/,
     vector<lp::LPConstraint> &constraints,
     double infinity) {
     assert(pattern_generator);
@@ -36,7 +37,7 @@
       create pattern_generator locally and no longer need to explicitly reset
       it.
     */
-    pattern_generator = nullptr;
+    //pattern_generator = nullptr;
     pdbs = pattern_collection_info.get_pdbs();
     TaskProxy task_proxy(*task);
     constraint_offset = constraints.size();
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/pho_constraints.h fast-downward/src/search/operator_counting/pho_constraints.h
--- fast-downward-original/src/search/operator_counting/pho_constraints.h	2020-10-26 22:55:33.082762100 -0300
+++ fast-downward/src/search/operator_counting/pho_constraints.h	2021-03-18 23:58:06.203964900 -0300
@@ -26,6 +26,7 @@
 
     virtual void initialize_constraints(
         const std::shared_ptr<AbstractTask> &task,
+        std::vector<lp::LPVariable> & /*variables*/,
         std::vector<lp::LPConstraint> &constraints,
         double infinity) override;
     virtual bool update_constraints(
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/state_equation_constraints.cc fast-downward/src/search/operator_counting/state_equation_constraints.cc
--- fast-downward-original/src/search/operator_counting/state_equation_constraints.cc	2020-10-26 22:55:33.086734100 -0300
+++ fast-downward/src/search/operator_counting/state_equation_constraints.cc	2021-03-18 23:58:06.203964900 -0300
@@ -68,7 +68,9 @@
 }
 
 void StateEquationConstraints::initialize_constraints(
-    const shared_ptr<AbstractTask> &task, vector<lp::LPConstraint> &constraints,
+    const shared_ptr<AbstractTask> &task, 
+    vector<lp::LPVariable> & /*variables*/,
+    vector<lp::LPConstraint> &constraints,
     double infinity) {
     utils::g_log << "Initializing constraints from state equation." << endl;
     TaskProxy task_proxy(*task);
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/operator_counting/state_equation_constraints.h fast-downward/src/search/operator_counting/state_equation_constraints.h
--- fast-downward-original/src/search/operator_counting/state_equation_constraints.h	2020-10-26 22:55:33.090722200 -0300
+++ fast-downward/src/search/operator_counting/state_equation_constraints.h	2021-03-18 23:58:06.203964900 -0300
@@ -34,6 +34,7 @@
     void add_constraints(std::vector<lp::LPConstraint> &constraints, double infinity);
 public:
     virtual void initialize_constraints(const std::shared_ptr<AbstractTask> &task,
+                                        std::vector<lp::LPVariable> & /*variables*/,
                                         std::vector<lp::LPConstraint> &constraints,
                                         double infinity);
     virtual bool update_constraints(const State &state, lp::LPSolver &lp_solver);
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/pdbs/explicit_projection.cc fast-downward/src/search/pdbs/explicit_projection.cc
--- fast-downward-original/src/search/pdbs/explicit_projection.cc	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/pdbs/explicit_projection.cc	2021-03-18 23:58:06.219586000 -0300
@@ -0,0 +1,513 @@
+#include "explicit_projection.h"
+
+#include "../utils/collections.h"
+#include "../utils/logging.h"
+#include "../utils/math.h"
+
+#include <limits>
+#include <unordered_map>
+
+using namespace std;
+
+namespace pdbs {
+int rank_state(const Pattern &pattern, const vector<int> &hash_multipliers,
+               const State &state) {
+    size_t index = 0;
+    for (size_t i = 0; i < pattern.size(); ++i) {
+        index += hash_multipliers[i] * state[pattern[i]].get_value();
+    }
+    return index;
+}
+
+int rank_abstract_state(const vector<int> &hash_multipliers,
+                        const vector<int> &state) {
+    size_t index = 0;
+    for (size_t i = 0; i < state.size(); ++i) {
+        index += hash_multipliers[i] * state[i];
+    }
+    return index;
+}
+
+vector<int> unrank_abstract_state(const Pattern &pattern,
+                                  const vector<int> &hash_multipliers,
+                                  int index) {
+    vector<int> values(pattern.size());
+    for (int i = pattern.size() - 1; i >= 0; --i) {
+        values[i] = index / hash_multipliers[i];
+        index -= values[i] * hash_multipliers[i];
+    }
+    assert(index == 0);
+    return values;
+}
+
+bool is_goal_state(const vector<int> &unranked, const vector<FactPair> &goals) {
+    for (FactPair goal : goals) {
+        if (unranked[goal.var] != goal.value) {
+            return false;
+        }
+    }
+    return true;
+}
+
+bool violates_mutex(const vector<int> &abstract_state,
+                    const pdbs::Pattern &pattern, const TaskProxy &task_proxy) {
+    VariablesProxy vars = task_proxy.get_variables();
+    int num_pattern_vars = pattern.size();
+    assert(num_pattern_vars == static_cast<int>(abstract_state.size()));
+    for (int i1 = 0; i1 < num_pattern_vars; ++i1) {
+        FactProxy f1 = vars[pattern[i1]].get_fact(abstract_state[i1]);
+        for (int i2 = i1 + 1; i2 < num_pattern_vars; ++i2) {
+            FactProxy f2 = vars[pattern[i2]].get_fact(abstract_state[i2]);
+            if (f1.is_mutex(f2)) {
+                return true;
+            }
+        }
+    }
+    return false;
+}
+
+int compute_hash_multipliers(const Pattern &pattern,
+                             const TaskProxy &task_proxy,
+                             vector<int> &hash_multipliers) {
+    assert(hash_multipliers.empty());
+    hash_multipliers.reserve(pattern.size());
+    int num_states = 1;
+    for (int pattern_var_id : pattern) {
+        hash_multipliers.push_back(num_states);
+        VariableProxy var = task_proxy.get_variables()[pattern_var_id];
+        if (utils::is_product_within_limit(num_states, var.get_domain_size(),
+                                           numeric_limits<int>::max())) {
+            num_states *= var.get_domain_size();
+        } else {
+            cerr << "Given pattern is too large! (Overflow occured): " << endl;
+            cerr << pattern << endl;
+            utils::exit_with(utils::ExitCode::SEARCH_CRITICAL_ERROR);
+        }
+    }
+
+    return num_states;
+}
+
+class ForwardAbstractOperator {
+   public:
+    vector<FactPair> preconditions;
+    int hash_effect;
+    int id;
+
+    ForwardAbstractOperator(int op_id, const vector<FactPair> &prev_pairs,
+                            const vector<FactPair> &pre_pairs,
+                            const vector<FactPair> &eff_pairs,
+                            const vector<int> &hash_multipliers);
+    bool is_appliable(const vector<int> &unranked) const;
+};
+
+ForwardAbstractOperator::ForwardAbstractOperator(
+    int op_id, const vector<FactPair> &prev_pairs,
+    const vector<FactPair> &pre_pairs, const vector<FactPair> &eff_pairs,
+    const vector<int> &hash_multipliers) {
+    id = op_id;
+
+    preconditions.insert(preconditions.end(), prev_pairs.begin(),
+                         prev_pairs.end());
+    preconditions.insert(preconditions.end(), pre_pairs.begin(),
+                         pre_pairs.end());
+
+    hash_effect = 0;
+    assert(pre_pairs.size() == eff_pairs.size());
+    for (size_t i = 0; i < pre_pairs.size(); ++i) {
+        int var = pre_pairs[i].var;
+        assert(var == eff_pairs[i].var);
+        int pre = pre_pairs[i].value;
+        int post = eff_pairs[i].value;
+        assert(pre != -1);
+        size_t effect = (post - pre) * hash_multipliers[var];
+        hash_effect += effect;
+    }
+}
+
+bool ForwardAbstractOperator::is_appliable(const vector<int> &unranked) const {
+    for (FactPair fact : preconditions) {
+        if (unranked[fact.var] != fact.value) {
+            return false;
+        }
+    }
+    return true;
+}
+
+void multiply_out(int op_id, int pos, vector<FactPair> &prev_pairs,
+                  vector<FactPair> &pre_pairs, vector<FactPair> &eff_pairs,
+                  const vector<FactPair> &effects_without_pre,
+                  const VariablesProxy &variables, const Pattern &pattern,
+                  const vector<int> &hash_multipliers,
+                  vector<ForwardAbstractOperator> &operators) {
+    if (pos == static_cast<int>(effects_without_pre.size())) {
+        // All effects without precondition have been checked: insert op.
+        operators.emplace_back(op_id, prev_pairs, pre_pairs, eff_pairs,
+                               hash_multipliers);
+    } else {
+        // For each possible value for the current variable, build an
+        // abstract operator.
+        int var_id = effects_without_pre[pos].var;
+        int eff = effects_without_pre[pos].value;
+        VariableProxy var = variables[pattern[var_id]];
+        for (int i = 0; i < var.get_domain_size(); ++i) {
+            if (i != eff) {
+                pre_pairs.emplace_back(var_id, i);
+                eff_pairs.emplace_back(var_id, eff);
+            } else {
+                prev_pairs.emplace_back(var_id, i);
+            }
+            multiply_out(op_id, pos + 1, prev_pairs, pre_pairs, eff_pairs,
+                         effects_without_pre, variables, pattern,
+                         hash_multipliers, operators);
+            if (i != eff) {
+                pre_pairs.pop_back();
+                eff_pairs.pop_back();
+            } else {
+                prev_pairs.pop_back();
+            }
+        }
+    }
+}
+
+bool build_abstract_operators(const OperatorProxy &op,
+                              const vector<int> &variable_to_index,
+                              const VariablesProxy &variables,
+                              const Pattern &pattern,
+                              const vector<int> &hash_multipliers,
+                              vector<ForwardAbstractOperator> &operators) {
+    // All variable value pairs that are a prevail condition
+    vector<FactPair> prev_pairs;
+    // All variable value pairs that are a precondition (value != -1)
+    vector<FactPair> pre_pairs;
+    // All variable value pairs that are an effect
+    vector<FactPair> eff_pairs;
+    // All variable value pairs that are a precondition (value = -1)
+    vector<FactPair> effects_without_pre;
+
+    size_t num_vars = variables.size();
+    vector<bool> has_precond_and_effect_on_var(num_vars, false);
+    vector<int> precondition_on_var(num_vars, -1);
+
+    for (FactProxy pre : op.get_preconditions())
+        precondition_on_var[pre.get_variable().get_id()] = pre.get_value();
+
+    for (EffectProxy eff : op.get_effects()) {
+        int var_id = eff.get_fact().get_variable().get_id();
+        int pattern_var_id = variable_to_index[var_id];
+        int val = eff.get_fact().get_value();
+        if (pattern_var_id != -1) {
+            if (precondition_on_var[var_id] != -1) {
+                if (precondition_on_var[var_id] != val) {
+                    has_precond_and_effect_on_var[var_id] = true;
+                    eff_pairs.emplace_back(pattern_var_id, val);
+                }
+            } else {
+                effects_without_pre.emplace_back(pattern_var_id, val);
+            }
+        }
+    }
+    for (FactProxy pre : op.get_preconditions()) {
+        int var_id = pre.get_variable().get_id();
+        int pattern_var_id = variable_to_index[var_id];
+        int val = pre.get_value();
+        if (pattern_var_id != -1) {  // variable occurs in pattern
+            if (has_precond_and_effect_on_var[var_id]) {
+                pre_pairs.emplace_back(pattern_var_id, val);
+            } else {
+                prev_pairs.emplace_back(pattern_var_id, val);
+            }
+        }
+    }
+    if (eff_pairs.empty() && effects_without_pre.empty() &&
+        prev_pairs.empty()) {
+        return false;
+    } else {
+        multiply_out(op.get_id(), 0, prev_pairs, pre_pairs, eff_pairs,
+                     effects_without_pre, variables, pattern, hash_multipliers,
+                     operators);
+        return true;
+    }
+}
+
+pair<AbstractionFunction, AbstractTransitionSystem> prune_transition_system(
+    const AbstractionFunction &alpha,
+    const AbstractTransitionSystem &transition_system, const vector<bool> &keep,
+    const vector<bool> &merge_to_dummy_state) {
+    vector<int> index_translation(transition_system.num_states, -1);
+    int num_remaining_states = 0;
+    if (!merge_to_dummy_state.empty()) {
+        // Use state 0 as a dummy state.
+        num_remaining_states = 1;
+    }
+    for (int old_state = 0; old_state < transition_system.num_states;
+         ++old_state) {
+        if (keep[old_state]) {
+            if (!merge_to_dummy_state.empty() &&
+                merge_to_dummy_state[old_state]) {
+                index_translation[old_state] = 0;
+            } else {
+                index_translation[old_state] = num_remaining_states;
+                ++num_remaining_states;
+            }
+        }
+    }
+
+    if (num_remaining_states == transition_system.num_states) {
+        return make_pair(alpha, transition_system);
+    }
+
+    AbstractTransitionSystem pruned_ts;
+    pruned_ts.num_states = num_remaining_states;
+
+    assert(keep[transition_system.initial_state]);
+    pruned_ts.initial_state =
+        index_translation[transition_system.initial_state];
+
+    for (int goal : transition_system.goal_states) {
+        if (keep[goal]) {
+            pruned_ts.goal_states.push_back(index_translation[goal]);
+        }
+    }
+    utils::sort_unique(pruned_ts.goal_states);
+
+    pruned_ts.self_loops_on_all_states =
+        transition_system.self_loops_on_all_states;
+
+    unordered_map<int, vector<int>> self_loops_by_op;
+    for (Transition t : transition_system.self_loops) {
+        int source = t.source;
+        if (keep[source]) {
+            self_loops_by_op[t.op_id].push_back(index_translation[source]);
+        }
+    }
+
+    for (Transition t : transition_system.state_changing_transitions) {
+        int source = t.source;
+        int target = t.target;
+        if (keep[source] && keep[target]) {
+            int new_source = index_translation[source];
+            int new_target = index_translation[target];
+            if (new_source == new_target) {
+                self_loops_by_op[t.op_id].push_back(new_source);
+            } else {
+                pruned_ts.state_changing_transitions.emplace_back(
+                    new_source, new_target, t.op_id);
+            }
+        }
+    }
+
+    for (auto &entry : self_loops_by_op) {
+        int op_id = entry.first;
+        vector<int> &sources = entry.second;
+        utils::sort_unique(sources);
+        if (static_cast<int>(sources.size()) == pruned_ts.num_states) {
+            pruned_ts.self_loops_on_all_states.push_back(op_id);
+        } else {
+            for (int source : sources) {
+                pruned_ts.self_loops.emplace_back(source, source, op_id);
+            }
+        }
+    }
+
+    AbstractionFunction alpha_pruned(alpha, move(index_translation));
+    return make_pair(alpha_pruned, pruned_ts);
+}
+
+AbstractionFunction::AbstractionFunction(const Pattern &pattern,
+                                         const vector<int> &hash_multipliers)
+    : pattern(pattern), hash_multipliers(hash_multipliers) {}
+
+AbstractionFunction::AbstractionFunction(const AbstractionFunction &other,
+                                         vector<int> &&index_translation)
+    : pattern(other.pattern),
+      hash_multipliers(other.hash_multipliers),
+      index_translation(move(index_translation)) {}
+
+int AbstractionFunction::get_abstract_state(const State &state) const {
+    int state_id = rank_state(pattern, hash_multipliers, state);
+    if (index_translation.empty()) {
+        return state_id;
+    } else {
+        assert(utils::in_bounds(state_id, index_translation));
+        return index_translation[state_id];
+    }
+}
+
+pair<AbstractionFunction, AbstractTransitionSystem> project_task(
+    const AbstractTask &task, const Pattern &pattern, bool remove_dead_states,
+    bool use_mutexes, const vector<vector<int>> &partial_merge_states) {
+    utils::unused_variable(remove_dead_states);
+    utils::unused_variable(use_mutexes);
+
+    TaskProxy task_proxy(task);
+    AbstractTransitionSystem transition_system;
+
+    vector<int> hash_multipliers;
+    transition_system.num_states =
+        compute_hash_multipliers(pattern, task_proxy, hash_multipliers);
+
+    VariablesProxy variables = task_proxy.get_variables();
+    vector<int> variable_to_index(variables.size(), -1);
+    for (size_t i = 0; i < pattern.size(); ++i) {
+        variable_to_index[pattern[i]] = i;
+    }
+
+    State task_initial_state = task_proxy.get_initial_state();
+    transition_system.initial_state =
+        rank_state(pattern, hash_multipliers, task_initial_state);
+
+    vector<FactPair> abstract_goal;
+    for (FactProxy goal : task_proxy.get_goals()) {
+        int var_pattern_index = variable_to_index[goal.get_variable().get_id()];
+        if (var_pattern_index != -1) {
+            abstract_goal.emplace_back(var_pattern_index, goal.get_value());
+        }
+    }
+
+    vector<ForwardAbstractOperator> abstract_operators;
+    for (OperatorProxy op : task_proxy.get_operators()) {
+        int op_relevant =
+            build_abstract_operators(op, variable_to_index, variables, pattern,
+                                     hash_multipliers, abstract_operators);
+        if (!op_relevant) {
+            transition_system.self_loops_on_all_states.push_back(op.get_id());
+        }
+    }
+
+    vector<bool> seen(transition_system.num_states, false);
+    vector<int> queue;
+    vector<vector<int>> inverse_transitions(transition_system.num_states);
+    queue.reserve(transition_system.num_states);
+    if (remove_dead_states) {
+        // Only generate states/transitions that are forward reachable.
+        queue.push_back(transition_system.initial_state);
+    } else {
+        // Generate all states/transitions.
+        for (int state = 0; state < transition_system.num_states; ++state) {
+            queue.push_back(state);
+        }
+    }
+    while (!queue.empty()) {
+        int source = queue.back();
+        queue.pop_back();
+
+        if (seen[source]) {
+            continue;
+        }
+        seen[source] = true;
+
+        vector<int> unranked =
+            unrank_abstract_state(pattern, hash_multipliers, source);
+        if (is_goal_state(unranked, abstract_goal)) {
+            transition_system.goal_states.push_back(source);
+        }
+
+        for (const ForwardAbstractOperator &op : abstract_operators) {
+            if (op.is_appliable(unranked)) {
+                if (op.hash_effect == 0) {
+                    transition_system.self_loops.emplace_back(source, source,
+                                                              op.id);
+                } else {
+                    int target = source + op.hash_effect;
+                    transition_system.state_changing_transitions.emplace_back(
+                        source, target, op.id);
+                    queue.push_back(target);
+                    inverse_transitions[target].push_back(source);
+                }
+            }
+        }
+    }
+
+    vector<bool> keep(seen);
+    if (use_mutexes) {
+        for (int state = 0; state < transition_system.num_states; ++state) {
+            if (keep[state]) {
+                vector<int> unranked =
+                    unrank_abstract_state(pattern, hash_multipliers, state);
+                keep[state] = !violates_mutex(unranked, pattern, task_proxy);
+            }
+        }
+    }
+
+    if (remove_dead_states) {
+        vector<bool> backwards_seen(transition_system.num_states, false);
+        vector<int> backwards_queue;
+        for (int goal : transition_system.goal_states) {
+            if (keep[goal]) {
+                backwards_queue.push_back(goal);
+            }
+        }
+        while (!backwards_queue.empty()) {
+            int target = backwards_queue.back();
+            backwards_queue.pop_back();
+
+            if (backwards_seen[target] || !keep[target]) {
+                continue;
+            }
+            backwards_seen[target] = true;
+
+            for (int source : inverse_transitions[target]) {
+                backwards_queue.push_back(source);
+            }
+        }
+        for (int state = 0; state < transition_system.num_states; ++state) {
+            keep[state] = keep[state] && backwards_seen[state];
+        }
+    }
+    keep[transition_system.initial_state] = true;
+
+    vector<bool> merge_to_dummy_state;
+    if (!partial_merge_states.empty()) {
+        merge_to_dummy_state.resize(transition_system.num_states, true);
+        for (const vector<int> &abstract_state : partial_merge_states) {
+            merge_to_dummy_state[rank_abstract_state(hash_multipliers,
+                                                     abstract_state)] = false;
+        }
+    }
+
+    AbstractionFunction alpha(pattern, hash_multipliers);
+    return prune_transition_system(alpha, transition_system, keep,
+                                   merge_to_dummy_state);
+}
+
+void dump(const AbstractTransitionSystem &ts) {
+    cout << "num_states: " << ts.num_states << endl;
+
+    cout << "init: " << ts.initial_state << endl;
+
+    cout << "goals: ";
+    for (int g : ts.goal_states) {
+        cout << g << ", ";
+    }
+    cout << endl;
+
+    cout << "irrelevant: ";
+    for (int i : ts.self_loops_on_all_states) {
+        cout << i << ", ";
+    }
+    cout << endl;
+
+    vector<vector<vector<int>>> transitions(ts.num_states,
+                                            vector<vector<int>>(ts.num_states));
+
+    for (Transition t : ts.state_changing_transitions) {
+        transitions[t.source][t.target].push_back(t.op_id);
+    }
+    for (Transition t : ts.self_loops) {
+        transitions[t.source][t.source].push_back(t.op_id);
+    }
+
+    cout << "Transitions:" << endl;
+    for (int source = 0; source < ts.num_states; ++source) {
+        for (int target = 0; target < ts.num_states; ++target) {
+            if (transitions[source][target].empty()) continue;
+            cout << source << " -> " << target << " [label=\"";
+            for (int op_id : transitions[source][target]) {
+                cout << op_id << ", ";
+            }
+            cout << "\"]" << endl;
+        }
+    }
+}
+}  // namespace pdbs
diff -X lp-recognizer/fd-patch.ignore -ruN fast-downward-original/src/search/pdbs/explicit_projection.h fast-downward/src/search/pdbs/explicit_projection.h
--- fast-downward-original/src/search/pdbs/explicit_projection.h	1969-12-31 21:00:00.000000000 -0300
+++ fast-downward/src/search/pdbs/explicit_projection.h	2021-03-18 23:58:06.219586000 -0300
@@ -0,0 +1,52 @@
+#ifndef PDBS_EXPLICIT_PROJECTION_H
+#define PDBS_EXPLICIT_PROJECTION_H
+
+#include "types.h"
+
+#include "../abstract_task.h"
+#include "../task_proxy.h"
+
+#include <vector>
+
+namespace pdbs {
+struct Transition {
+    int source;
+    int target;
+    int op_id;
+
+    Transition(int source, int target, int op_id)
+        : source(source), target(target), op_id(op_id) {}
+};
+
+struct AbstractTransitionSystem {
+    int num_states;
+    int initial_state;
+    std::vector<int> goal_states;
+    std::vector<Transition> state_changing_transitions;
+    std::vector<Transition> self_loops;
+    std::vector<int> self_loops_on_all_states;
+};
+
+class AbstractionFunction {
+    std::vector<int> pattern;
+    std::vector<int> hash_multipliers;
+    std::vector<int> index_translation;
+
+   public:
+    AbstractionFunction(const Pattern &pattern,
+                        const std::vector<int> &hash_multipliers);
+    AbstractionFunction(const AbstractionFunction &other,
+                        std::vector<int> &&index_translation);
+    int get_abstract_state(const State &state) const;
+};
+
+std::pair<AbstractionFunction, AbstractTransitionSystem> project_task(
+    const AbstractTask &task, const Pattern &pattern,
+    bool remove_dead_states = true, bool use_mutexes = false,
+    const std::vector<std::vector<int>> &partial_merge_states =
+        std::vector<std::vector<int>>());
+
+void dump(const AbstractTransitionSystem &ts);
+}  // namespace pdbs
+
+#endif
Binary files fast-downward-original/src/search.zip and fast-downward/src/search.zip differ
